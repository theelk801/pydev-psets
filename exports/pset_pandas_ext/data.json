[{"p":"\"\"\"\n1. How to import pandas and check the version?\n\"\"\"\n\"\"\"\n \n\"\"\"\n","s":"\"\"\"\n1. How to import pandas and check the version?\n\"\"\"\n\"\"\"\n \n\"\"\"\n\nimport numpy as np  # optional\nimport pandas as pd\nprint(pd.__version__)\nprint(pd.show_versions(as_json=True))"},{"p":"\"\"\"\n2. How to create a series from a list, numpy array and dict?\n\"\"\"\n\"\"\"\nCreate a pandas series from each of the items below: a list, numpy and a dictionary\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\nimport numpy as np\nmylist = list('abcedfghijklmnopqrstuvwxyz')\nmyarr = np.arange(26)\nmydict = dict(zip(mylist, myarr))\n\"\"\"\n","s":"\"\"\"\n2. How to create a series from a list, numpy array and dict?\n\"\"\"\n\"\"\"\nCreate a pandas series from each of the items below: a list, numpy and a dictionary\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\nimport numpy as np\nmylist = list('abcedfghijklmnopqrstuvwxyz')\nmyarr = np.arange(26)\nmydict = dict(zip(mylist, myarr))\n\"\"\"\n\n# Inputs\nimport numpy as np\nmylist = list('abcedfghijklmnopqrstuvwxyz')\nmyarr = np.arange(26)\nmydict = dict(zip(mylist, myarr))\n\n# Solution\nser1 = pd.Series(mylist)\nser2 = pd.Series(myarr)\nser3 = pd.Series(mydict)\nprint(ser3.head())"},{"p":"\"\"\"\n3. How to convert the index of a series into a column of a dataframe?\n\"\"\"\n\"\"\"\nDifficulty Level: L1\n\"\"\"\n\"\"\"\nConvert the series ser into a dataframe with its index as another column on the dataframe.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\nmylist = list('abcedfghijklmnopqrstuvwxyz')\nmyarr = np.arange(26)\nmydict = dict(zip(mylist, myarr))\nser = pd.Series(mydict)\n\"\"\"\n","s":"\"\"\"\n3. How to convert the index of a series into a column of a dataframe?\n\"\"\"\n\"\"\"\nDifficulty Level: L1\n\"\"\"\n\"\"\"\nConvert the series ser into a dataframe with its index as another column on the dataframe.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\nmylist = list('abcedfghijklmnopqrstuvwxyz')\nmyarr = np.arange(26)\nmydict = dict(zip(mylist, myarr))\nser = pd.Series(mydict)\n\"\"\"\n\n# Input\nmylist = list('abcedfghijklmnopqrstuvwxyz')\nmyarr = np.arange(26)\nmydict = dict(zip(mylist, myarr))\nser = pd.Series(mydict)\n\n# Solution\ndf = ser.to_frame().reset_index()\nprint(df.head())"},{"p":"\"\"\"\n4. How to combine many series to form a dataframe?\n\"\"\"\n\"\"\"\nDifficulty Level: L1\n\"\"\"\n\"\"\"\nCombine ser1 and ser2 to form a dataframe.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\nimport numpy as np\nser1 = pd.Series(list('abcedfghijklmnopqrstuvwxyz'))\nser2 = pd.Series(np.arange(26))\n\"\"\"\n","s":"\"\"\"\n4. How to combine many series to form a dataframe?\n\"\"\"\n\"\"\"\nDifficulty Level: L1\n\"\"\"\n\"\"\"\nCombine ser1 and ser2 to form a dataframe.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\nimport numpy as np\nser1 = pd.Series(list('abcedfghijklmnopqrstuvwxyz'))\nser2 = pd.Series(np.arange(26))\n\"\"\"\n\n# Input\nimport numpy as np\nser1 = pd.Series(list('abcedfghijklmnopqrstuvwxyz'))\nser2 = pd.Series(np.arange(26))\n\n# Solution 1\ndf = pd.concat([ser1, ser2], axis=1)\n\n# Solution 2\ndf = pd.DataFrame({'col1': ser1, 'col2': ser2})\nprint(df.head())"},{"p":"\"\"\"\n5. How to assign name to the series’ index?\n\"\"\"\n\"\"\"\nDifficulty Level: L1\n\"\"\"\n\"\"\"\nGive a name to the series ser calling it ‘alphabets’.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\nser = pd.Series(list('abcedfghijklmnopqrstuvwxyz'))\n\"\"\"\n","s":"\"\"\"\n5. How to assign name to the series’ index?\n\"\"\"\n\"\"\"\nDifficulty Level: L1\n\"\"\"\n\"\"\"\nGive a name to the series ser calling it ‘alphabets’.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\nser = pd.Series(list('abcedfghijklmnopqrstuvwxyz'))\n\"\"\"\n\n# Input\nser = pd.Series(list('abcedfghijklmnopqrstuvwxyz'))\n\n# Solution\nser.name = 'alphabets'\nser.head()"},{"p":"\"\"\"\n6. How to get the items of series A not present in series B?\n\"\"\"\n\"\"\"\nDifficulty Level: L2\n\"\"\"\n\"\"\"\nFrom ser1 remove items present in ser2.\n\"\"\"\n\"\"\"\nser1 = pd.Series([1, 2, 3, 4, 5])\nser2 = pd.Series([4, 5, 6, 7, 8])\n\"\"\"\n","s":"\"\"\"\n6. How to get the items of series A not present in series B?\n\"\"\"\n\"\"\"\nDifficulty Level: L2\n\"\"\"\n\"\"\"\nFrom ser1 remove items present in ser2.\n\"\"\"\n\"\"\"\nser1 = pd.Series([1, 2, 3, 4, 5])\nser2 = pd.Series([4, 5, 6, 7, 8])\n\"\"\"\n\n# Input\nser1 = pd.Series([1, 2, 3, 4, 5])\nser2 = pd.Series([4, 5, 6, 7, 8])\n\n# Solution\nser1[~ser1.isin(ser2)]"},{"p":"\"\"\"\n7. How to get the items not common to both series A and series B?\n\"\"\"\n\"\"\"\nDifficulty Level: L2\n\"\"\"\n\"\"\"\nGet all items of ser1 and ser2 not common to both.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\nser1 = pd.Series([1, 2, 3, 4, 5])\nser2 = pd.Series([4, 5, 6, 7, 8])\n\"\"\"\n","s":"\"\"\"\n7. How to get the items not common to both series A and series B?\n\"\"\"\n\"\"\"\nDifficulty Level: L2\n\"\"\"\n\"\"\"\nGet all items of ser1 and ser2 not common to both.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\nser1 = pd.Series([1, 2, 3, 4, 5])\nser2 = pd.Series([4, 5, 6, 7, 8])\n\"\"\"\n\n# Input\nser1 = pd.Series([1, 2, 3, 4, 5])\nser2 = pd.Series([4, 5, 6, 7, 8])\n\n# Solution\nser_u = pd.Series(np.union1d(ser1, ser2))  # union\nser_i = pd.Series(np.intersect1d(ser1, ser2))  # intersect\nser_u[~ser_u.isin(ser_i)]"},{"p":"\"\"\"\n8. How to get the minimum, 25th percentile, median, 75th, and max of a numeric series?\n\"\"\"\n\"\"\"\nDifficuty Level: L2\n\"\"\"\n\"\"\"\nCompute the minimum, 25th percentile, median, 75th, and maximum of ser.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\nser = pd.Series(np.random.normal(10, 5, 25))\n\"\"\"\n","s":"\"\"\"\n8. How to get the minimum, 25th percentile, median, 75th, and max of a numeric series?\n\"\"\"\n\"\"\"\nDifficuty Level: L2\n\"\"\"\n\"\"\"\nCompute the minimum, 25th percentile, median, 75th, and maximum of ser.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\nser = pd.Series(np.random.normal(10, 5, 25))\n\"\"\"\n\n# Input\nstate = np.random.RandomState(100)\nser = pd.Series(state.normal(10, 5, 25))\n\n# Solution\nnp.percentile(ser, q=[0, 25, 50, 75, 100])"},{"p":"\"\"\"\n9. How to get frequency counts of unique items of a series?\n\"\"\"\n\"\"\"\nDifficulty Level: L1\n\"\"\"\n\"\"\"\nCalculte the frequency counts of each unique value ser.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\nser = pd.Series(np.take(list('abcdefgh'), np.random.randint(8, size=30)))\n\"\"\"\n","s":"\"\"\"\n9. How to get frequency counts of unique items of a series?\n\"\"\"\n\"\"\"\nDifficulty Level: L1\n\"\"\"\n\"\"\"\nCalculte the frequency counts of each unique value ser.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\nser = pd.Series(np.take(list('abcdefgh'), np.random.randint(8, size=30)))\n\"\"\"\n\n# Input\nser = pd.Series(np.take(list('abcdefgh'), np.random.randint(8, size=30)))\n\n# Solution\nser.value_counts()"},{"p":"\"\"\"\n10. How to keep only top 2 most frequent values as it is and replace everything else as ‘Other’?\n\"\"\"\n\"\"\"\nDifficulty Level: L2\n\"\"\"\n\"\"\"\nFrom ser, keep the top 2 most frequent items as it is and replace everything else as ‘Other’.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\nnp.random.RandomState(100)\nser = pd.Series(np.random.randint(1, 5, [12]))\n\"\"\"\n","s":"\"\"\"\n10. How to keep only top 2 most frequent values as it is and replace everything else as ‘Other’?\n\"\"\"\n\"\"\"\nDifficulty Level: L2\n\"\"\"\n\"\"\"\nFrom ser, keep the top 2 most frequent items as it is and replace everything else as ‘Other’.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\nnp.random.RandomState(100)\nser = pd.Series(np.random.randint(1, 5, [12]))\n\"\"\"\n\n# Input\nnp.random.RandomState(100)\nser = pd.Series(np.random.randint(1, 5, [12]))\n\n# Solution\nprint(\"Top 2 Freq:\", ser.value_counts())\nser[~ser.isin(ser.value_counts().index[:2])] = 'Other'\nser"},{"p":"\"\"\"\n11. How to bin a numeric series to 10 groups of equal size?\n\"\"\"\n\"\"\"\nDifficulty Level: L2\n\"\"\"\n\"\"\"\nBin the series ser into 10 equal deciles and replace the values with the bin name.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\nser = pd.Series(np.random.random(20))\n\"\"\"\n\"\"\"\nDesired Output\n\"\"\"\n\"\"\"\n# First 5 items\n0    7th\n1    9th\n2    7th\n3    3rd\n4    8th\ndtype: category\nCategories (10, object): [1st < 2nd < 3rd < 4th ... 7th < 8th < 9th < 10th]\n\"\"\"\n","s":"\"\"\"\n11. How to bin a numeric series to 10 groups of equal size?\n\"\"\"\n\"\"\"\nDifficulty Level: L2\n\"\"\"\n\"\"\"\nBin the series ser into 10 equal deciles and replace the values with the bin name.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\nser = pd.Series(np.random.random(20))\n\"\"\"\n\"\"\"\nDesired Output\n\"\"\"\n\"\"\"\n# First 5 items\n0    7th\n1    9th\n2    7th\n3    3rd\n4    8th\ndtype: category\nCategories (10, object): [1st < 2nd < 3rd < 4th ... 7th < 8th < 9th < 10th]\n\"\"\"\n\n# Input\nser = pd.Series(np.random.random(20))\nprint(ser.head())\n\n# Solution\npd.qcut(ser, q=[0, .10, .20, .3, .4, .5, .6, .7, .8, .9, 1], \n        labels=['1st', '2nd', '3rd', '4th', '5th', '6th', '7th', '8th', '9th', '10th']).head()"},{"p":"\"\"\"\n12. How to convert a numpy array to a dataframe of given shape? (L1)\n\"\"\"\n\"\"\"\nDifficulty Level: L1\n\"\"\"\n\"\"\"\nReshape the series ser into a dataframe with 7 rows and 5 columns\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\nser = pd.Series(np.random.randint(1, 10, 35))\n\"\"\"\n","s":"\"\"\"\n12. How to convert a numpy array to a dataframe of given shape? (L1)\n\"\"\"\n\"\"\"\nDifficulty Level: L1\n\"\"\"\n\"\"\"\nReshape the series ser into a dataframe with 7 rows and 5 columns\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\nser = pd.Series(np.random.randint(1, 10, 35))\n\"\"\"\n\n# Input\nser = pd.Series(np.random.randint(1, 10, 35))\n\n# Solution\ndf = pd.DataFrame(ser.values.reshape(7,5))\nprint(df)"},{"p":"\"\"\"\n13. How to find the positions of numbers that are multiples of 3 from a series?\n\"\"\"\n\"\"\"\nDifficulty Level: L2\n\"\"\"\n\"\"\"\nFind the positions of numbers that are multiples of 3 from ser.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\nser = pd.Series(np.random.randint(1, 10, 7))\n\"\"\"\n","s":"\"\"\"\n13. How to find the positions of numbers that are multiples of 3 from a series?\n\"\"\"\n\"\"\"\nDifficulty Level: L2\n\"\"\"\n\"\"\"\nFind the positions of numbers that are multiples of 3 from ser.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\nser = pd.Series(np.random.randint(1, 10, 7))\n\"\"\"\n\n# Input\nser = pd.Series(np.random.randint(1, 10, 7))\nser\n\n# Solution\nprint(ser)\nnp.argwhere(ser % 3==0)"},{"p":"\"\"\"\n14. How to extract items at given positions from a series\n\"\"\"\n\"\"\"\nDifficulty Level: L1\n\"\"\"\n\"\"\"\nFrom ser, extract the items at positions in list pos.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\nser = pd.Series(list('abcdefghijklmnopqrstuvwxyz'))\npos = [0, 4, 8, 14, 20]\n\"\"\"\n","s":"\"\"\"\n14. How to extract items at given positions from a series\n\"\"\"\n\"\"\"\nDifficulty Level: L1\n\"\"\"\n\"\"\"\nFrom ser, extract the items at positions in list pos.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\nser = pd.Series(list('abcdefghijklmnopqrstuvwxyz'))\npos = [0, 4, 8, 14, 20]\n\"\"\"\n\n# Input\nser = pd.Series(list('abcdefghijklmnopqrstuvwxyz'))\npos = [0, 4, 8, 14, 20]\n\n# Solution\nser.take(pos)"},{"p":"\"\"\"\n15. How to stack two series vertically and horizontally ?\n\"\"\"\n\"\"\"\nDifficulty Level: L1\n\"\"\"\n\"\"\"\nStack ser1 and ser2 vertically and horizontally (to form a dataframe).\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\nser1 = pd.Series(range(5))\nser2 = pd.Series(list('abcde'))\n\"\"\"\n","s":"\"\"\"\n15. How to stack two series vertically and horizontally ?\n\"\"\"\n\"\"\"\nDifficulty Level: L1\n\"\"\"\n\"\"\"\nStack ser1 and ser2 vertically and horizontally (to form a dataframe).\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\nser1 = pd.Series(range(5))\nser2 = pd.Series(list('abcde'))\n\"\"\"\n\n# Input\nser1 = pd.Series(range(5))\nser2 = pd.Series(list('abcde'))\n\n# Output\n# Vertical\nser1.append(ser2)\n\n# Horizontal\ndf = pd.concat([ser1, ser2], axis=1)\nprint(df)"},{"p":"\"\"\"\n16. How to get the positions of items of series A in another series B?\n\"\"\"\n\"\"\"\nDifficulty Level: L2\n\"\"\"\n\"\"\"\nGet the positions of items of ser2 in ser1 as a list.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\nser1 = pd.Series([10, 9, 6, 5, 3, 1, 12, 8, 13])\nser2 = pd.Series([1, 3, 10, 13])\n\"\"\"\n","s":"\"\"\"\n16. How to get the positions of items of series A in another series B?\n\"\"\"\n\"\"\"\nDifficulty Level: L2\n\"\"\"\n\"\"\"\nGet the positions of items of ser2 in ser1 as a list.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\nser1 = pd.Series([10, 9, 6, 5, 3, 1, 12, 8, 13])\nser2 = pd.Series([1, 3, 10, 13])\n\"\"\"\n\n# Input\nser1 = pd.Series([10, 9, 6, 5, 3, 1, 12, 8, 13])\nser2 = pd.Series([1, 3, 10, 13])\n\n# Solution 1\n[np.where(i == ser1)[0].tolist()[0] for i in ser2]\n\n# Solution 2\n[pd.Index(ser1).get_loc(i) for i in ser2]"},{"p":"\"\"\"\n17. How to compute the mean squared error on a truth and predicted series?\n\"\"\"\n\"\"\"\nDifficulty Level: L2\n\"\"\"\n\"\"\"\nCompute the mean squared error of truth and pred series.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\ntruth = pd.Series(range(10))\npred = pd.Series(range(10)) + np.random.random(10)\n\"\"\"\n","s":"\"\"\"\n17. How to compute the mean squared error on a truth and predicted series?\n\"\"\"\n\"\"\"\nDifficulty Level: L2\n\"\"\"\n\"\"\"\nCompute the mean squared error of truth and pred series.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\ntruth = pd.Series(range(10))\npred = pd.Series(range(10)) + np.random.random(10)\n\"\"\"\n\n# Input\ntruth = pd.Series(range(10))\npred = pd.Series(range(10)) + np.random.random(10)\n\n# Solution\nnp.mean((truth-pred)**2)"},{"p":"\"\"\"\n18. How to convert the first character of each element in a series to uppercase?\n\"\"\"\n\"\"\"\nDifficulty Level: L2\n\"\"\"\n\"\"\"\nChange the first character of each word to upper case in each word of ser.\n\"\"\"\n\"\"\"\nser = pd.Series(['how', 'to', 'kick', 'ass?'])\n\"\"\"\n","s":"\"\"\"\n18. How to convert the first character of each element in a series to uppercase?\n\"\"\"\n\"\"\"\nDifficulty Level: L2\n\"\"\"\n\"\"\"\nChange the first character of each word to upper case in each word of ser.\n\"\"\"\n\"\"\"\nser = pd.Series(['how', 'to', 'kick', 'ass?'])\n\"\"\"\n\n# Input\nser = pd.Series(['how', 'to', 'kick', 'ass?'])\n\n# Solution 1\nser.map(lambda x: x.title())\n\n# Solution 2\nser.map(lambda x: x[0].upper() + x[1:])\n\n# Solution 3\npd.Series([i.title() for i in ser])"},{"p":"\"\"\"\n19. How to calculate the number of characters in each word in a series?\n\"\"\"\n\"\"\"\nDifficulty Level: L2\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\nser = pd.Series(['how', 'to', 'kick', 'ass?'])\n\"\"\"\n","s":"\"\"\"\n19. How to calculate the number of characters in each word in a series?\n\"\"\"\n\"\"\"\nDifficulty Level: L2\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\nser = pd.Series(['how', 'to', 'kick', 'ass?'])\n\"\"\"\n\n# Input\nser = pd.Series(['how', 'to', 'kick', 'ass?'])\n\n# Solution\nser.map(lambda x: len(x))"},{"p":"\"\"\"\n20. How to compute difference of differences between consequtive numbers of a series?\n\"\"\"\n\"\"\"\nDifficulty Level: L1\n\"\"\"\n\"\"\"\nDifference of differences between the consequtive numbers of ser.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\nser = pd.Series([1, 3, 6, 10, 15, 21, 27, 35])\n\"\"\"\n\"\"\"\nDesired Output\n\"\"\"\n\"\"\"\n[nan, 2.0, 3.0, 4.0, 5.0, 6.0, 6.0, 8.0]\n[nan, nan, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0]\n\"\"\"\n","s":"\"\"\"\n20. How to compute difference of differences between consequtive numbers of a series?\n\"\"\"\n\"\"\"\nDifficulty Level: L1\n\"\"\"\n\"\"\"\nDifference of differences between the consequtive numbers of ser.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\nser = pd.Series([1, 3, 6, 10, 15, 21, 27, 35])\n\"\"\"\n\"\"\"\nDesired Output\n\"\"\"\n\"\"\"\n[nan, 2.0, 3.0, 4.0, 5.0, 6.0, 6.0, 8.0]\n[nan, nan, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0]\n\"\"\"\n\n# Input\nser = pd.Series([1, 3, 6, 10, 15, 21, 27, 35])\n\n# Solution\nprint(ser.diff().tolist())\nprint(ser.diff().diff().tolist())"},{"p":"\"\"\"\n21. How to convert a series of date-strings to a timeseries?\n\"\"\"\n\"\"\"\nDifficiulty Level: L2\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\nser = pd.Series(['01 Jan 2010', '02-02-2011', '20120303', '2013/04/04', '2014-05-05', '2015-06-06T12:20'])\n\"\"\"\n\"\"\"\nDesired Output\n\"\"\"\n\"\"\"\n0   2010-01-01 00:00:00\n1   2011-02-02 00:00:00\n2   2012-03-03 00:00:00\n3   2013-04-04 00:00:00\n4   2014-05-05 00:00:00\n5   2015-06-06 12:20:00\ndtype: datetime64[ns]\n\"\"\"\n","s":"\"\"\"\n21. How to convert a series of date-strings to a timeseries?\n\"\"\"\n\"\"\"\nDifficiulty Level: L2\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\nser = pd.Series(['01 Jan 2010', '02-02-2011', '20120303', '2013/04/04', '2014-05-05', '2015-06-06T12:20'])\n\"\"\"\n\"\"\"\nDesired Output\n\"\"\"\n\"\"\"\n0   2010-01-01 00:00:00\n1   2011-02-02 00:00:00\n2   2012-03-03 00:00:00\n3   2013-04-04 00:00:00\n4   2014-05-05 00:00:00\n5   2015-06-06 12:20:00\ndtype: datetime64[ns]\n\"\"\"\n\n# Input\nser = pd.Series(['01 Jan 2010', '02-02-2011', '20120303', '2013/04/04', '2014-05-05', '2015-06-06T12:20'])\n\n# Solution 1\nfrom dateutil.parser import parse\nser.map(lambda x: parse(x))\n\n# Solution 2\npd.to_datetime(ser)"},{"p":"\"\"\"\n22. How to get the day of month, week number, day of year and day of week from a series of date strings?\n\"\"\"\n\"\"\"\nDifficiulty Level: L2\n\"\"\"\n\"\"\"\nGet the day of month, week number, day of year and day of week from ser.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\nser = pd.Series(['01 Jan 2010', '02-02-2011', '20120303', '2013/04/04', '2014-05-05', '2015-06-06T12:20'])\n\"\"\"\n\"\"\"\nDesired output\n\"\"\"\n\"\"\"\nDate:  [1, 2, 3, 4, 5, 6]\nWeek number:  [53, 5, 9, 14, 19, 23]\nDay num of year:  [1, 33, 63, 94, 125, 157]\nDay of week:  ['Friday', 'Wednesday', 'Saturday', 'Thursday', 'Monday', 'Saturday']\n\"\"\"\n","s":"\"\"\"\n22. How to get the day of month, week number, day of year and day of week from a series of date strings?\n\"\"\"\n\"\"\"\nDifficiulty Level: L2\n\"\"\"\n\"\"\"\nGet the day of month, week number, day of year and day of week from ser.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\nser = pd.Series(['01 Jan 2010', '02-02-2011', '20120303', '2013/04/04', '2014-05-05', '2015-06-06T12:20'])\n\"\"\"\n\"\"\"\nDesired output\n\"\"\"\n\"\"\"\nDate:  [1, 2, 3, 4, 5, 6]\nWeek number:  [53, 5, 9, 14, 19, 23]\nDay num of year:  [1, 33, 63, 94, 125, 157]\nDay of week:  ['Friday', 'Wednesday', 'Saturday', 'Thursday', 'Monday', 'Saturday']\n\"\"\"\n\n# Input\nser = pd.Series(['01 Jan 2010', '02-02-2011', '20120303', '2013/04/04', '2014-05-05', '2015-06-06T12:20'])\n\n# Solution\nfrom dateutil.parser import parse\nser_ts = ser.map(lambda x: parse(x))\n\n# day of month\nprint(\"Date: \", ser_ts.dt.day.tolist())\n\n# week number\nprint(\"Week number: \", ser_ts.dt.weekofyear.tolist())\n\n# day of year\nprint(\"Day number of year: \", ser_ts.dt.dayofyear.tolist())\n\n# day of week\nprint(\"Day of week: \", ser_ts.dt.weekday_name.tolist())"},{"p":"\"\"\"\n23. How to convert year-month string to dates corresponding to the 4th day of the month?\n\"\"\"\n\"\"\"\nDifficiulty Level: L2\n\"\"\"\n\"\"\"\nChange ser to dates that start with 4th of the respective months.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\nser = pd.Series(['Jan 2010', 'Feb 2011', 'Mar 2012'])\n\"\"\"\n\"\"\"\nDesired Output\n\"\"\"\n\"\"\"\n0   2010-01-04\n1   2011-02-04\n2   2012-03-04\ndtype: datetime64[ns]\n\"\"\"\n","s":"\"\"\"\n23. How to convert year-month string to dates corresponding to the 4th day of the month?\n\"\"\"\n\"\"\"\nDifficiulty Level: L2\n\"\"\"\n\"\"\"\nChange ser to dates that start with 4th of the respective months.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\nser = pd.Series(['Jan 2010', 'Feb 2011', 'Mar 2012'])\n\"\"\"\n\"\"\"\nDesired Output\n\"\"\"\n\"\"\"\n0   2010-01-04\n1   2011-02-04\n2   2012-03-04\ndtype: datetime64[ns]\n\"\"\"\n\nimport pandas as pd\n# Input\nser = pd.Series(['Jan 2010', 'Feb 2011', 'Mar 2012'])\n\n# Solution 1\nfrom dateutil.parser import parse\n# Parse the date\nser_ts = ser.map(lambda x: parse(x))\n\n# Construct date string with date as 4\nser_datestr = ser_ts.dt.year.astype('str') + '-' + ser_ts.dt.month.astype('str') + '-' + '04'\n\n# Format it.\n[parse(i).strftime('%Y-%m-%d') for i in ser_datestr]\n\n# Solution 2\nser.map(lambda x: parse('04 ' + x))"},{"p":"\"\"\"\n24. How to filter words that contain atleast 2 vowels from a series?\n\"\"\"\n\"\"\"\nDifficiulty Level: L3\n\"\"\"\n\"\"\"\nFrom ser, extract words that contain atleast 2 vowels.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\nser = pd.Series(['Apple', 'Orange', 'Plan', 'Python', 'Money'])\n\"\"\"\n\"\"\"\nDesired Output\n\"\"\"\n\"\"\"\n0     Apple\n1    Orange\n4     Money\ndtype: object\n\"\"\"\n","s":"\"\"\"\n24. How to filter words that contain atleast 2 vowels from a series?\n\"\"\"\n\"\"\"\nDifficiulty Level: L3\n\"\"\"\n\"\"\"\nFrom ser, extract words that contain atleast 2 vowels.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\nser = pd.Series(['Apple', 'Orange', 'Plan', 'Python', 'Money'])\n\"\"\"\n\"\"\"\nDesired Output\n\"\"\"\n\"\"\"\n0     Apple\n1    Orange\n4     Money\ndtype: object\n\"\"\"\n\n# Input\nser = pd.Series(['Apple', 'Orange', 'Plan', 'Python', 'Money'])\n\n# Solution\nfrom collections import Counter\nmask = ser.map(lambda x: sum([Counter(x.lower()).get(i, 0) for i in list('aeiou')]) >= 2)\nser[mask]"},{"p":"\"\"\"\n25. How to filter valid emails from a series?\n\"\"\"\n\"\"\"\nDifficiulty Level: L3\n\"\"\"\n\"\"\"\nExtract the valid emails from the series emails. The regex pattern for valid emails is provided as reference.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\nemails = pd.Series(['buying books at amazom.com', 'rameses@egypt.com', 'matt@t.co', 'narendra@modi.com'])\npattern ='[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\\\.[A-Za-z]{2,4}'\n\"\"\"\n\"\"\"\nDesired Output\n\"\"\"\n\"\"\"\n1    rameses@egypt.com\n2            matt@t.co\n3    narendra@modi.com\ndtype: object\n\"\"\"\n","s":"\"\"\"\n25. How to filter valid emails from a series?\n\"\"\"\n\"\"\"\nDifficiulty Level: L3\n\"\"\"\n\"\"\"\nExtract the valid emails from the series emails. The regex pattern for valid emails is provided as reference.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\nemails = pd.Series(['buying books at amazom.com', 'rameses@egypt.com', 'matt@t.co', 'narendra@modi.com'])\npattern ='[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\\\.[A-Za-z]{2,4}'\n\"\"\"\n\"\"\"\nDesired Output\n\"\"\"\n\"\"\"\n1    rameses@egypt.com\n2            matt@t.co\n3    narendra@modi.com\ndtype: object\n\"\"\"\n\n# Input\nemails = pd.Series(['buying books at amazom.com', 'rameses@egypt.com', 'matt@t.co', 'narendra@modi.com'])\n\n# Solution 1 (as series of strings)\nimport re\npattern ='[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\\\.[A-Za-z]{2,4}'\nmask = emails.map(lambda x: bool(re.match(pattern, x)))\nemails[mask]\n\n# Solution 2 (as series of list)\nemails.str.findall(pattern, flags=re.IGNORECASE)\n\n# Solution 3 (as list)\n[x[0] for x in [re.findall(pattern, email) for email in emails] if len(x) > 0]"},{"p":"\"\"\"\n26. How to get the mean of a series grouped by another series?\n\"\"\"\n\"\"\"\nDifficiulty Level: L2\n\"\"\"\n\"\"\"\nCompute the mean of weights of each fruit.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\nfruit = pd.Series(np.random.choice(['apple', 'banana', 'carrot'], 10))\nweights = pd.Series(np.linspace(1, 10, 10))\nprint(weight.tolist())\nprint(fruit.tolist())\n#> [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0]\n#> ['banana', 'carrot', 'apple', 'carrot', 'carrot', 'apple', 'banana', 'carrot', 'apple', 'carrot']\n\"\"\"\n\"\"\"\nDesired output\n\"\"\"\n\"\"\"\n# values can change due to randomness\napple     6.0\nbanana    4.0\ncarrot    5.8\ndtype: float64\n\"\"\"\n","s":"\"\"\"\n26. How to get the mean of a series grouped by another series?\n\"\"\"\n\"\"\"\nDifficiulty Level: L2\n\"\"\"\n\"\"\"\nCompute the mean of weights of each fruit.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\nfruit = pd.Series(np.random.choice(['apple', 'banana', 'carrot'], 10))\nweights = pd.Series(np.linspace(1, 10, 10))\nprint(weight.tolist())\nprint(fruit.tolist())\n#> [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0]\n#> ['banana', 'carrot', 'apple', 'carrot', 'carrot', 'apple', 'banana', 'carrot', 'apple', 'carrot']\n\"\"\"\n\"\"\"\nDesired output\n\"\"\"\n\"\"\"\n# values can change due to randomness\napple     6.0\nbanana    4.0\ncarrot    5.8\ndtype: float64\n\"\"\"\n\n# Input\nfruit = pd.Series(np.random.choice(['apple', 'banana', 'carrot'], 10))\nweights = pd.Series(np.linspace(1, 10, 10))\n\n# Solution\nweights.groupby(fruit).mean()"},{"p":"\"\"\"\n27. How to compute the euclidean distance between two series?\n\"\"\"\n\"\"\"\nDifficiulty Level: L2\n\"\"\"\n\"\"\"\nCompute the euclidean distance between series (points) p and q, without using a packaged formula.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\np = pd.Series([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\nq = pd.Series([10, 9, 8, 7, 6, 5, 4, 3, 2, 1])\n\"\"\"\n\"\"\"\nDesired Output\n\"\"\"\n\"\"\"\n18.165\n\"\"\"\n","s":"\"\"\"\n27. How to compute the euclidean distance between two series?\n\"\"\"\n\"\"\"\nDifficiulty Level: L2\n\"\"\"\n\"\"\"\nCompute the euclidean distance between series (points) p and q, without using a packaged formula.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\np = pd.Series([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\nq = pd.Series([10, 9, 8, 7, 6, 5, 4, 3, 2, 1])\n\"\"\"\n\"\"\"\nDesired Output\n\"\"\"\n\"\"\"\n18.165\n\"\"\"\n\n# Input\np = pd.Series([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\nq = pd.Series([10, 9, 8, 7, 6, 5, 4, 3, 2, 1])\n\n# Solution \nsum((p - q)**2)**.5\n\n# Solution (using func)\nnp.linalg.norm(p-q)"},{"p":"\"\"\"\n28. How to find all the local maxima (or peaks) in a numeric series?\n\"\"\"\n\"\"\"\nDifficiulty Level: L3\n\"\"\"\n\"\"\"\nGet the positions of peaks (values surrounded by smaller values on both sides) in ser.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\nser = pd.Series([2, 10, 3, 4, 9, 10, 2, 7, 3])\n\"\"\"\n\"\"\"\nDesired output\n\"\"\"\n\"\"\"\narray([1, 5, 7])\n\"\"\"\n","s":"\"\"\"\n28. How to find all the local maxima (or peaks) in a numeric series?\n\"\"\"\n\"\"\"\nDifficiulty Level: L3\n\"\"\"\n\"\"\"\nGet the positions of peaks (values surrounded by smaller values on both sides) in ser.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\nser = pd.Series([2, 10, 3, 4, 9, 10, 2, 7, 3])\n\"\"\"\n\"\"\"\nDesired output\n\"\"\"\n\"\"\"\narray([1, 5, 7])\n\"\"\"\n\n# Input\nser = pd.Series([2, 10, 3, 4, 9, 10, 2, 7, 3])\n\n# Solution\ndd = np.diff(np.sign(np.diff(ser)))\npeak_locs = np.where(dd == -2)[0] + 1\npeak_locs"},{"p":"\"\"\"\n29. How to replace missing spaces in a string with the least frequent character?\n\"\"\"\n\"\"\"\nReplace the spaces in my_str with the least frequent character.\n\"\"\"\n\"\"\"\nDifficiulty Level: L2\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\nmy_str = 'dbc deb abed gade'\n\"\"\"\n\"\"\"\nDesired Output\n\"\"\"\n\"\"\"\n'dbccdebcabedcgade'  # least frequent is 'c'\n\"\"\"\n","s":"\"\"\"\n29. How to replace missing spaces in a string with the least frequent character?\n\"\"\"\n\"\"\"\nReplace the spaces in my_str with the least frequent character.\n\"\"\"\n\"\"\"\nDifficiulty Level: L2\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\nmy_str = 'dbc deb abed gade'\n\"\"\"\n\"\"\"\nDesired Output\n\"\"\"\n\"\"\"\n'dbccdebcabedcgade'  # least frequent is 'c'\n\"\"\"\n\n# Input\nmy_str = 'dbc deb abed gade'\n\n# Solution\nser = pd.Series(list('dbc deb abed gade'))\nfreq = ser.value_counts()\nprint(freq)\nleast_freq = freq.dropna().index[-1]\n\"\".join(ser.replace(' ', least_freq))"},{"p":"\"\"\"\n30. How to create a TimeSeries starting ‘2000-01-01’ and 10 weekends (saturdays) after that having random numbers as values?\n\"\"\"\n\"\"\"\nDifficiulty Level: L2\n\"\"\"\n\"\"\"\nDesired output\n\"\"\"\n\"\"\"\n# values can be random\n2000-01-01    4\n2000-01-08    1\n2000-01-15    8\n2000-01-22    4\n2000-01-29    4\n2000-02-05    2\n2000-02-12    4\n2000-02-19    9\n2000-02-26    6\n2000-03-04    6\n\"\"\"\n","s":"\"\"\"\n30. How to create a TimeSeries starting ‘2000-01-01’ and 10 weekends (saturdays) after that having random numbers as values?\n\"\"\"\n\"\"\"\nDifficiulty Level: L2\n\"\"\"\n\"\"\"\nDesired output\n\"\"\"\n\"\"\"\n# values can be random\n2000-01-01    4\n2000-01-08    1\n2000-01-15    8\n2000-01-22    4\n2000-01-29    4\n2000-02-05    2\n2000-02-12    4\n2000-02-19    9\n2000-02-26    6\n2000-03-04    6\n\"\"\"\n\n# Solution\nser = pd.Series(np.random.randint(1,10,10), pd.date_range('2000-01-01', periods=10, freq='W-SAT'))\nser"},{"p":"\"\"\"\n31. How to fill an intermittent time series so all missing dates show up with values of previous non-missing date?\n\"\"\"\n\"\"\"\nDifficiulty Level: L2\n\"\"\"\n\"\"\"\nser has missing dates and values. Make all missing dates appear and fill up with value from previous date.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\nser = pd.Series([1,10,3,np.nan], index=pd.to_datetime(['2000-01-01', '2000-01-03', '2000-01-06', '2000-01-08']))\nprint(ser)\n#> 2000-01-01     1.0\n#> 2000-01-03    10.0\n#> 2000-01-06     3.0\n#> 2000-01-08     NaN\n#> dtype: float64\n\"\"\"\n\"\"\"\nDesired Output\n\"\"\"\n\"\"\"\n2000-01-01     1.0\n2000-01-02     1.0\n2000-01-03    10.0\n2000-01-04    10.0\n2000-01-05    10.0\n2000-01-06     3.0\n2000-01-07     3.0\n2000-01-08     NaN\n\"\"\"\n","s":"\"\"\"\n31. How to fill an intermittent time series so all missing dates show up with values of previous non-missing date?\n\"\"\"\n\"\"\"\nDifficiulty Level: L2\n\"\"\"\n\"\"\"\nser has missing dates and values. Make all missing dates appear and fill up with value from previous date.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\nser = pd.Series([1,10,3,np.nan], index=pd.to_datetime(['2000-01-01', '2000-01-03', '2000-01-06', '2000-01-08']))\nprint(ser)\n#> 2000-01-01     1.0\n#> 2000-01-03    10.0\n#> 2000-01-06     3.0\n#> 2000-01-08     NaN\n#> dtype: float64\n\"\"\"\n\"\"\"\nDesired Output\n\"\"\"\n\"\"\"\n2000-01-01     1.0\n2000-01-02     1.0\n2000-01-03    10.0\n2000-01-04    10.0\n2000-01-05    10.0\n2000-01-06     3.0\n2000-01-07     3.0\n2000-01-08     NaN\n\"\"\"\n\n# Input\nser = pd.Series([1,10,3, np.nan], index=pd.to_datetime(['2000-01-01', '2000-01-03', '2000-01-06', '2000-01-08']))\n\n# Solution\nser.resample('D').ffill()  # fill with previous value\n\n# Alternatives\nser.resample('D').bfill()  # fill with next value\nser.resample('D').bfill().ffill()  # fill next else prev value"},{"p":"\"\"\"\n32. How to compute the autocorrelations of a numeric series?\n\"\"\"\n\"\"\"\nDifficiulty Level: L3\n\"\"\"\n\"\"\"\nCompute autocorrelations for the first 10 lags of ser. Find out which lag has the largest correlation.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\nser = pd.Series(np.arange(20) + np.random.normal(1, 10, 20))\n\"\"\"\n\"\"\"\nDesired output\n\"\"\"\n\"\"\"\n# values will change due to randomness\n[0.29999999999999999, -0.11, -0.17000000000000001, 0.46000000000000002, 0.28000000000000003, -0.040000000000000001, -0.37, 0.41999999999999998, 0.47999999999999998, 0.17999999999999999]\nLag having highest correlation:  9\n\"\"\"\n","s":"\"\"\"\n32. How to compute the autocorrelations of a numeric series?\n\"\"\"\n\"\"\"\nDifficiulty Level: L3\n\"\"\"\n\"\"\"\nCompute autocorrelations for the first 10 lags of ser. Find out which lag has the largest correlation.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\nser = pd.Series(np.arange(20) + np.random.normal(1, 10, 20))\n\"\"\"\n\"\"\"\nDesired output\n\"\"\"\n\"\"\"\n# values will change due to randomness\n[0.29999999999999999, -0.11, -0.17000000000000001, 0.46000000000000002, 0.28000000000000003, -0.040000000000000001, -0.37, 0.41999999999999998, 0.47999999999999998, 0.17999999999999999]\nLag having highest correlation:  9\n\"\"\"\n\n# Input\nser = pd.Series(np.arange(20) + np.random.normal(1, 10, 20))\n\n# Solution\nautocorrelations = [ser.autocorr(i).round(2) for i in range(11)]\nprint(autocorrelations[1:])\nprint('Lag having highest correlation: ', np.argmax(np.abs(autocorrelations[1:]))+1)"},{"p":"\"\"\"\n33. How to import only every nth row from a csv file to create a dataframe?\n\"\"\"\n\"\"\"\nDifficiulty Level: L2\n\"\"\"\n\"\"\"\nImport every 50th row of BostonHousing dataset as a dataframe.\n\"\"\"\n\"\"\"\n \n\"\"\"\n","s":"\"\"\"\n33. How to import only every nth row from a csv file to create a dataframe?\n\"\"\"\n\"\"\"\nDifficiulty Level: L2\n\"\"\"\n\"\"\"\nImport every 50th row of BostonHousing dataset as a dataframe.\n\"\"\"\n\"\"\"\n \n\"\"\"\n\n# Solution 1: Use chunks and for-loop\ndf = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv', chunksize=50)\ndf2 = pd.DataFrame()\nfor chunk in df:\n    df2 = df2.append(chunk.iloc[0,:])\n\n\n# Solution 2: Use chunks and list comprehension\ndf = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv', chunksize=50)\ndf2 = pd.concat([chunk.iloc[0] for chunk in df], axis=1)\ndf2 = df2.transpose()\n\n# Solution 3: Use csv reader\nimport csv          \nwith open('BostonHousing.csv', 'r') as f:\n    reader = csv.reader(f)\n    out = []\n    for i, row in enumerate(reader):\n        if i%50 == 0:\n            out.append(row)\n\ndf2 = pd.DataFrame(out[1:], columns=out[0])\nprint(df2.head())"},{"p":"\"\"\"\n34. How to change column values when importing csv to a dataframe?\n\"\"\"\n\"\"\"\nDifficulty Level: L2\n\"\"\"\n\"\"\"\nImport the boston housing dataset, but while importing change the 'medv' (median house value) column so that values < 25 becomes ‘Low’ and > 25 becomes ‘High’.\n\"\"\"\n\"\"\"\n \n\"\"\"\n","s":"\"\"\"\n34. How to change column values when importing csv to a dataframe?\n\"\"\"\n\"\"\"\nDifficulty Level: L2\n\"\"\"\n\"\"\"\nImport the boston housing dataset, but while importing change the 'medv' (median house value) column so that values < 25 becomes ‘Low’ and > 25 becomes ‘High’.\n\"\"\"\n\"\"\"\n \n\"\"\"\n\n# Solution 1: Using converter parameter\ndf = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv', \n                 converters={'medv': lambda x: 'High' if float(x) > 25 else 'Low'})\n\n\n# Solution 2: Using csv reader\nimport csv\nwith open('BostonHousing.csv', 'r') as f:\n    reader = csv.reader(f)\n    out = []\n    for i, row in enumerate(reader):\n        if i > 0:\n            row[13] = 'High' if float(row[13]) > 25 else 'Low'\n        out.append(row)\n\ndf = pd.DataFrame(out[1:], columns=out[0])\nprint(df.head())"},{"p":"\"\"\"\n35. How to create a dataframe with rows as strides from a given series?\n\"\"\"\n\"\"\"\nDifficiulty Level: L3\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\nL = pd.Series(range(15))\n\"\"\"\n\"\"\"\nDesired Output\n\"\"\"\n\"\"\"\narray([[ 0,  1,  2,  3],\n       [ 2,  3,  4,  5],\n       [ 4,  5,  6,  7],\n       [ 6,  7,  8,  9],\n       [ 8,  9, 10, 11],\n       [10, 11, 12, 13]])\n\"\"\"\n","s":"\"\"\"\n35. How to create a dataframe with rows as strides from a given series?\n\"\"\"\n\"\"\"\nDifficiulty Level: L3\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\nL = pd.Series(range(15))\n\"\"\"\n\"\"\"\nDesired Output\n\"\"\"\n\"\"\"\narray([[ 0,  1,  2,  3],\n       [ 2,  3,  4,  5],\n       [ 4,  5,  6,  7],\n       [ 6,  7,  8,  9],\n       [ 8,  9, 10, 11],\n       [10, 11, 12, 13]])\n\"\"\"\n\nL = pd.Series(range(15))\n\ndef gen_strides(a, stride_len=5, window_len=5):\n    n_strides = ((a.size-window_len)//stride_len) + 1\n    return np.array([a[s:(s+window_len)] for s in np.arange(0, a.size, stride_len)[:n_strides]])\n\ngen_strides(L, stride_len=2, window_len=4)"},{"p":"\"\"\"\n36. How to import only specified columns from a csv file?\n\"\"\"\n\"\"\"\nDifficulty Level: L1\n\"\"\"\n\"\"\"\nImport ‘crim’ and ‘medv’ columns of the BostonHousing dataset as a dataframe.\n\"\"\"\n\"\"\"\n \n\"\"\"\n","s":"\"\"\"\n36. How to import only specified columns from a csv file?\n\"\"\"\n\"\"\"\nDifficulty Level: L1\n\"\"\"\n\"\"\"\nImport ‘crim’ and ‘medv’ columns of the BostonHousing dataset as a dataframe.\n\"\"\"\n\"\"\"\n \n\"\"\"\n\ndf = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv', usecols=['crim', 'medv'])\nprint(df.head())"},{"p":"\"\"\"\n37. How to get the nrows, ncolumns, datatype, summary stats of each column of a dataframe? Also get the array and list equivalent.\n\"\"\"\n\"\"\"\nDifficulty Level: L2\n\"\"\"\n\"\"\"\nGet the number of rows, columns, datatype and summary statistics of each column of the Cars93 dataset. Also get the numpy array and list equivalent of the dataframe.\n\"\"\"\n\"\"\"\n \n\"\"\"\n","s":"\"\"\"\n37. How to get the nrows, ncolumns, datatype, summary stats of each column of a dataframe? Also get the array and list equivalent.\n\"\"\"\n\"\"\"\nDifficulty Level: L2\n\"\"\"\n\"\"\"\nGet the number of rows, columns, datatype and summary statistics of each column of the Cars93 dataset. Also get the numpy array and list equivalent of the dataframe.\n\"\"\"\n\"\"\"\n \n\"\"\"\n\ndf = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n\n#  number of rows and columns\nprint(df.shape)\n\n# datatypes\nprint(df.dtypes)\n\n# how many columns under each dtype\nprint(df.get_dtype_counts())\nprint(df.dtypes.value_counts())\n\n# summary statistics\ndf_stats = df.describe()\n\n# numpy array \ndf_arr = df.values\n\n# list\ndf_list = df.values.tolist()"},{"p":"\"\"\"\n38. How to extract the row and column number of a particular cell with given criterion?\n\"\"\"\n\"\"\"\nDifficulty Level: L1\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\ndf = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n\"\"\"\n\"\"\"\nWhich manufacturer, model and type has the highest Price? What is the row and column number of the cell with the highest Price value?\n\"\"\"\n\"\"\"\n \n\"\"\"\n","s":"\"\"\"\n38. How to extract the row and column number of a particular cell with given criterion?\n\"\"\"\n\"\"\"\nDifficulty Level: L1\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\ndf = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n\"\"\"\n\"\"\"\nWhich manufacturer, model and type has the highest Price? What is the row and column number of the cell with the highest Price value?\n\"\"\"\n\"\"\"\n \n\"\"\"\n\n# Input\ndf = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n\n# Solution\n# Get Manufacturer with highest price\ndf.loc[df.Price == np.max(df.Price), ['Manufacturer', 'Model', 'Type']]\n\n# Get Row and Column number\nrow, col = np.where(df.values == np.max(df.Price))\n\n# Get the value\ndf.iat[row[0], col[0]]\ndf.iloc[row[0], col[0]]\n\n# Alternates\ndf.at[row[0], 'Price']\ndf.get_value(row[0], 'Price')\n\n# The difference between `iat` - `iloc` vs `at` - `loc` is:\n# `iat` snd `iloc` accepts row and column numbers. \n# Whereas `at` and `loc` accepts index and column names."},{"p":"\"\"\"\n39. How to rename a specific columns in a dataframe?\n\"\"\"\n\"\"\"\nDifficulty Level: L2\n\"\"\"\n\"\"\"\nRename the column Type as CarType in df and replace the ‘.’ in column names with ‘_’.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\ndf = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\nprint(df.columns)\n#> Index(['Manufacturer', 'Model', 'Type', 'Min.Price', 'Price', 'Max.Price',\n#>        'MPG.city', 'MPG.highway', 'AirBags', 'DriveTrain', 'Cylinders',\n#>        'EngineSize', 'Horsepower', 'RPM', 'Rev.per.mile', 'Man.trans.avail',\n#>        'Fuel.tank.capacity', 'Passengers', 'Length', 'Wheelbase', 'Width',\n#>        'Turn.circle', 'Rear.seat.room', 'Luggage.room', 'Weight', 'Origin',\n#>        'Make'],\n#>       dtype='object')\n\"\"\"\n\"\"\"\nDesired Solution\n\"\"\"\n\"\"\"\nprint(df.columns)\n#> Index(['Manufacturer', 'Model', 'CarType', 'Min_Price', 'Price', 'Max_Price',\n#>        'MPG_city', 'MPG_highway', 'AirBags', 'DriveTrain', 'Cylinders',\n#>        'EngineSize', 'Horsepower', 'RPM', 'Rev_per_mile', 'Man_trans_avail',\n#>        'Fuel_tank_capacity', 'Passengers', 'Length', 'Wheelbase', 'Width',\n#>        'Turn_circle', 'Rear_seat_room', 'Luggage_room', 'Weight', 'Origin',\n#>        'Make'],\n#>       dtype='object')\n\"\"\"\n","s":"\"\"\"\n39. How to rename a specific columns in a dataframe?\n\"\"\"\n\"\"\"\nDifficulty Level: L2\n\"\"\"\n\"\"\"\nRename the column Type as CarType in df and replace the ‘.’ in column names with ‘_’.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\ndf = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\nprint(df.columns)\n#> Index(['Manufacturer', 'Model', 'Type', 'Min.Price', 'Price', 'Max.Price',\n#>        'MPG.city', 'MPG.highway', 'AirBags', 'DriveTrain', 'Cylinders',\n#>        'EngineSize', 'Horsepower', 'RPM', 'Rev.per.mile', 'Man.trans.avail',\n#>        'Fuel.tank.capacity', 'Passengers', 'Length', 'Wheelbase', 'Width',\n#>        'Turn.circle', 'Rear.seat.room', 'Luggage.room', 'Weight', 'Origin',\n#>        'Make'],\n#>       dtype='object')\n\"\"\"\n\"\"\"\nDesired Solution\n\"\"\"\n\"\"\"\nprint(df.columns)\n#> Index(['Manufacturer', 'Model', 'CarType', 'Min_Price', 'Price', 'Max_Price',\n#>        'MPG_city', 'MPG_highway', 'AirBags', 'DriveTrain', 'Cylinders',\n#>        'EngineSize', 'Horsepower', 'RPM', 'Rev_per_mile', 'Man_trans_avail',\n#>        'Fuel_tank_capacity', 'Passengers', 'Length', 'Wheelbase', 'Width',\n#>        'Turn_circle', 'Rear_seat_room', 'Luggage_room', 'Weight', 'Origin',\n#>        'Make'],\n#>       dtype='object')\n\"\"\"\n\n# Input\ndf = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n\n# Solution\n# Step 1:\ndf=df.rename(columns = {'Type':'CarType'})\n# or\ndf.columns.values[2] = \"CarType\"\n\n# Step 2:\ndf.columns = df.columns.map(lambda x: x.replace('.', '_'))\nprint(df.columns)"},{"p":"\"\"\"\n40. How to check if a dataframe has any missing values?\n\"\"\"\n\"\"\"\nDifficulty Level: L1\n\"\"\"\n\"\"\"\nCheck if df has any missing values.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\ndf = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n\"\"\"\n","s":"\"\"\"\n40. How to check if a dataframe has any missing values?\n\"\"\"\n\"\"\"\nDifficulty Level: L1\n\"\"\"\n\"\"\"\nCheck if df has any missing values.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\ndf = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n\"\"\"\n\n# Input\ndf = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n\n# Solution\ndf.isnull().values.any()"},{"p":"\"\"\"\n41. How to count the number of missing values in each column?\n\"\"\"\n\"\"\"\nDifficulty Level: L2\n\"\"\"\n\"\"\"\nCount the number of missing values in each column of df. Which column has the maximum number of missing values?\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\ndf = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n\"\"\"\n","s":"\"\"\"\n41. How to count the number of missing values in each column?\n\"\"\"\n\"\"\"\nDifficulty Level: L2\n\"\"\"\n\"\"\"\nCount the number of missing values in each column of df. Which column has the maximum number of missing values?\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\ndf = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n\"\"\"\n\n# Input\ndf = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n\n# Solution\nn_missings_each_col = df.apply(lambda x: x.isnull().sum())\nn_missings_each_col.argmax()"},{"p":"\"\"\"\n42. How to replace missing values of multiple numeric columns with the mean?\n\"\"\"\n\"\"\"\nDifficulty Level: L2\n\"\"\"\n\"\"\"\nReplace missing values in Min.Price and Max.Price columns with their respective mean.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\ndf = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n\"\"\"\n","s":"\"\"\"\n42. How to replace missing values of multiple numeric columns with the mean?\n\"\"\"\n\"\"\"\nDifficulty Level: L2\n\"\"\"\n\"\"\"\nReplace missing values in Min.Price and Max.Price columns with their respective mean.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\ndf = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n\"\"\"\n\n# Input\ndf = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n\n# Solution\ndf_out = df[['Min.Price', 'Max.Price']] = df[['Min.Price', 'Max.Price']].apply(lambda x: x.fillna(x.mean()))\nprint(df_out.head())"},{"p":"\"\"\"\n43. How to use apply function on existing columns with global variables as additional arguments?\n\"\"\"\n\"\"\"\nDifficulty Level: L3\n\"\"\"\n\"\"\"\nIn df, use apply method to replace the missing values in Min.Price with the column’s mean and those in Max.Price with the column’s median.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\ndf = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n\"\"\"\n\"\"\"\nUse Hint from StackOverflow\n\"\"\"\n\"\"\"\n \n\"\"\"\n","s":"\"\"\"\n43. How to use apply function on existing columns with global variables as additional arguments?\n\"\"\"\n\"\"\"\nDifficulty Level: L3\n\"\"\"\n\"\"\"\nIn df, use apply method to replace the missing values in Min.Price with the column’s mean and those in Max.Price with the column’s median.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\ndf = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n\"\"\"\n\"\"\"\nUse Hint from StackOverflow\n\"\"\"\n\"\"\"\n \n\"\"\"\n\n# Input\ndf = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n\n# Solution\nd = {'Min.Price': np.nanmean, 'Max.Price': np.nanmedian}\ndf[['Min.Price', 'Max.Price']] = df[['Min.Price', 'Max.Price']].apply(lambda x, d: x.fillna(d[x.name](x)), args=(d, ))"},{"p":"\"\"\"\n44. How to select a specific column from a dataframe as a dataframe instead of a series?\n\"\"\"\n\"\"\"\nDifficulty Level: L2\n\"\"\"\n\"\"\"\nGet the first column (a) in df as a dataframe (rather than as a Series).\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\ndf = pd.DataFrame(np.arange(20).reshape(-1, 5), columns=list('abcde'))\n\"\"\"\n","s":"\"\"\"\n44. How to select a specific column from a dataframe as a dataframe instead of a series?\n\"\"\"\n\"\"\"\nDifficulty Level: L2\n\"\"\"\n\"\"\"\nGet the first column (a) in df as a dataframe (rather than as a Series).\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\ndf = pd.DataFrame(np.arange(20).reshape(-1, 5), columns=list('abcde'))\n\"\"\"\n\n# Input\ndf = pd.DataFrame(np.arange(20).reshape(-1, 5), columns=list('abcde'))\n\n# Solution\ntype(df[['a']])\ntype(df.loc[:, ['a']])\ntype(df.iloc[:, [0]])\n\n# Alternately the following returns a Series\ntype(df.a)\ntype(df['a'])\ntype(df.loc[:, 'a'])\ntype(df.iloc[:, 1])"},{"p":"\"\"\"\n45. How to change the order of columns of a dataframe?\n\"\"\"\n\"\"\"\nDifficulty Level: L3\n\"\"\"\n\"\"\"\nActually 3 questions.\n\"\"\"\n\"\"\"\nIn df, interchange columns 'a' and 'c'.Create a generic function to interchange two columns, without hardcoding column names.Sort the columns in reverse alphabetical order, that is colume 'e' first through column 'a' last.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\ndf = pd.DataFrame(np.arange(20).reshape(-1, 5), columns=list('abcde'))\n\"\"\"\n","s":"\"\"\"\n45. How to change the order of columns of a dataframe?\n\"\"\"\n\"\"\"\nDifficulty Level: L3\n\"\"\"\n\"\"\"\nActually 3 questions.\n\"\"\"\n\"\"\"\nIn df, interchange columns 'a' and 'c'.Create a generic function to interchange two columns, without hardcoding column names.Sort the columns in reverse alphabetical order, that is colume 'e' first through column 'a' last.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\ndf = pd.DataFrame(np.arange(20).reshape(-1, 5), columns=list('abcde'))\n\"\"\"\n\n# Input\ndf = pd.DataFrame(np.arange(20).reshape(-1, 5), columns=list('abcde'))\n\n# Solution Q1\ndf[list('cbade')]\n\n# Solution Q2 - No hard coding\ndef switch_columns(df, col1=None, col2=None):\n    colnames = df.columns.tolist()\n    i1, i2 = colnames.index(col1), colnames.index(col2)\n    colnames[i2], colnames[i1] = colnames[i1], colnames[i2]\n    return df[colnames]\n\ndf1 = switch_columns(df, 'a', 'c')\n\n# Solution Q3\ndf[sorted(df.columns)]\n# or\ndf.sort_index(axis=1, ascending=False, inplace=True)"},{"p":"\"\"\"\n46. How to set the number of rows and columns displayed in the output?\n\"\"\"\n\"\"\"\nDifficulty Level: L2\n\"\"\"\n\"\"\"\nChange the pamdas display settings on printing the dataframe df it shows a maximum of 10 rows and 10 columns.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\ndf = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n\"\"\"\n","s":"\"\"\"\n46. How to set the number of rows and columns displayed in the output?\n\"\"\"\n\"\"\"\nDifficulty Level: L2\n\"\"\"\n\"\"\"\nChange the pamdas display settings on printing the dataframe df it shows a maximum of 10 rows and 10 columns.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\ndf = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n\"\"\"\n\n# Input\ndf = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n\n# Solution\npd.set_option('display.max_columns', 10)\npd.set_option('display.max_rows', 10)\n# df\n\n# Show all available options\n# pd.describe_option()"},{"p":"\"\"\"\n47. How to format or suppress scientific notations in a pandas dataframe?\n\"\"\"\n\"\"\"\nDifficulty Level: L2\n\"\"\"\n\"\"\"\nSuppress scientific notations like ‘e-03’ in df and print upto 4 numbers after decimal.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\ndf = pd.DataFrame(np.random.random(4)**10, columns=['random'])\ndf\n#>          random\n#> 0  3.474280e-03\n#> 1  3.951517e-05\n#> 2  7.469702e-02\n#> 3  5.541282e-28\n\"\"\"\n\"\"\"\nDesired Output\n\"\"\"\n\"\"\"\n#>    random\n#> 0  0.0035\n#> 1  0.0000\n#> 2  0.0747\n#> 3  0.0000\n\"\"\"\n","s":"\"\"\"\n47. How to format or suppress scientific notations in a pandas dataframe?\n\"\"\"\n\"\"\"\nDifficulty Level: L2\n\"\"\"\n\"\"\"\nSuppress scientific notations like ‘e-03’ in df and print upto 4 numbers after decimal.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\ndf = pd.DataFrame(np.random.random(4)**10, columns=['random'])\ndf\n#>          random\n#> 0  3.474280e-03\n#> 1  3.951517e-05\n#> 2  7.469702e-02\n#> 3  5.541282e-28\n\"\"\"\n\"\"\"\nDesired Output\n\"\"\"\n\"\"\"\n#>    random\n#> 0  0.0035\n#> 1  0.0000\n#> 2  0.0747\n#> 3  0.0000\n\"\"\"\n\n# Input\ndf = pd.DataFrame(np.random.random(4)**10, columns=['random'])\n\n# Solution 1: Rounding\ndf.round(4)\n\n# Solution 2: Use apply to change format\ndf.apply(lambda x: '%.4f' % x, axis=1)\n# or\ndf.applymap(lambda x: '%.4f' % x)\n\n# Solution 3: Use set_option\npd.set_option('display.float_format', lambda x: '%.4f' % x)\n\n# Solution 4: Assign display.float_format\npd.options.display.float_format = '{:.4f}'.format\nprint(df)\n\n# Reset/undo float formatting\npd.options.display.float_format = None"},{"p":"\"\"\"\n48. How to format all the values in a dataframe as percentages?\n\"\"\"\n\"\"\"\nDifficulty Level: L2\n\"\"\"\n\"\"\"\nFormat the values in column 'random' of df as percentages.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\ndf = pd.DataFrame(np.random.random(4), columns=['random'])\ndf\n#>      random\n#> 0    .689723\n#> 1    .957224\n#> 2    .159157\n#> 3    .21082\n\"\"\"\n\"\"\"\nDesired Output\n\"\"\"\n\"\"\"\n#>      random\n#> 0    68.97%\n#> 1    95.72%\n#> 2    15.91%\n#> 3    2.10%\n\"\"\"\n","s":"\"\"\"\n48. How to format all the values in a dataframe as percentages?\n\"\"\"\n\"\"\"\nDifficulty Level: L2\n\"\"\"\n\"\"\"\nFormat the values in column 'random' of df as percentages.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\ndf = pd.DataFrame(np.random.random(4), columns=['random'])\ndf\n#>      random\n#> 0    .689723\n#> 1    .957224\n#> 2    .159157\n#> 3    .21082\n\"\"\"\n\"\"\"\nDesired Output\n\"\"\"\n\"\"\"\n#>      random\n#> 0    68.97%\n#> 1    95.72%\n#> 2    15.91%\n#> 3    2.10%\n\"\"\"\n\n# Input\ndf = pd.DataFrame(np.random.random(4), columns=['random'])\n\n# Solution\nout = df.style.format({\n    'random': '{0:.2%}'.format,\n})\n\nout"},{"p":"\"\"\"\n49. How to filter every nth row in a dataframe?\n\"\"\"\n\"\"\"\nDifficulty Level: L1\n\"\"\"\n\"\"\"\nFrom df, filter the 'Manufacturer', 'Model' and 'Type' for every 20th row starting from 1st (row 0).\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\ndf = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n\"\"\"\n","s":"\"\"\"\n49. How to filter every nth row in a dataframe?\n\"\"\"\n\"\"\"\nDifficulty Level: L1\n\"\"\"\n\"\"\"\nFrom df, filter the 'Manufacturer', 'Model' and 'Type' for every 20th row starting from 1st (row 0).\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\ndf = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n\"\"\"\n\n# Input\ndf = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n\n# Solution\nprint(df.iloc[::20, :][['Manufacturer', 'Model', 'Type']])"},{"p":"\"\"\"\n50. How to create a primary key index by combining relevant columns?\n\"\"\"\n\"\"\"\nDifficulty Level: L2\n\"\"\"\n\"\"\"\nIn df, Replace NaNs with ‘missing’ in columns 'Manufacturer', 'Model' and 'Type' and create a index as a combination of these three columns and check if the index is a primary key.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\ndf = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv', usecols=[0,1,2,3,5])\n\"\"\"\n\"\"\"\nDesired Output\n\"\"\"\n\"\"\"\n                       Manufacturer    Model     Type  Min.Price  Max.Price\nAcura_Integra_Small           Acura  Integra    Small       12.9       18.8\nmissing_Legend_Midsize      missing   Legend  Midsize       29.2       38.7\nAudi_90_Compact                Audi       90  Compact       25.9       32.3\nAudi_100_Midsize               Audi      100  Midsize        NaN       44.6\nBMW_535i_Midsize                BMW     535i  Midsize        NaN        NaN\n\"\"\"\n","s":"\"\"\"\n50. How to create a primary key index by combining relevant columns?\n\"\"\"\n\"\"\"\nDifficulty Level: L2\n\"\"\"\n\"\"\"\nIn df, Replace NaNs with ‘missing’ in columns 'Manufacturer', 'Model' and 'Type' and create a index as a combination of these three columns and check if the index is a primary key.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\ndf = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv', usecols=[0,1,2,3,5])\n\"\"\"\n\"\"\"\nDesired Output\n\"\"\"\n\"\"\"\n                       Manufacturer    Model     Type  Min.Price  Max.Price\nAcura_Integra_Small           Acura  Integra    Small       12.9       18.8\nmissing_Legend_Midsize      missing   Legend  Midsize       29.2       38.7\nAudi_90_Compact                Audi       90  Compact       25.9       32.3\nAudi_100_Midsize               Audi      100  Midsize        NaN       44.6\nBMW_535i_Midsize                BMW     535i  Midsize        NaN        NaN\n\"\"\"\n\n# Input\ndf = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv', usecols=[0,1,2,3,5])\n\n# Solution\ndf[['Manufacturer', 'Model', 'Type']] = df[['Manufacturer', 'Model', 'Type']].fillna('missing')\ndf.index = df.Manufacturer + '_' + df.Model + '_' + df.Type\nprint(df.index.is_unique)"},{"p":"\"\"\"\n51. How to get the row number of the nth largest value in a column?\n\"\"\"\n\"\"\"\nDifficulty Level: L2\n\"\"\"\n\"\"\"\nFind the row position of the 5th largest value of column 'a' in df.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\ndf = pd.DataFrame(np.random.randint(1, 30, 30).reshape(10,-1), columns=list('abc'))\n\"\"\"\n","s":"\"\"\"\n51. How to get the row number of the nth largest value in a column?\n\"\"\"\n\"\"\"\nDifficulty Level: L2\n\"\"\"\n\"\"\"\nFind the row position of the 5th largest value of column 'a' in df.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\ndf = pd.DataFrame(np.random.randint(1, 30, 30).reshape(10,-1), columns=list('abc'))\n\"\"\"\n\n# Input\ndf = pd.DataFrame(np.random.randint(1, 30, 30).reshape(10,-1), columns=list('abc'))\n\n# Solution\nn = 5\ndf['a'].argsort()[::-1][n]"},{"p":"\"\"\"\n52. How to find the position of the nth largest value greater than a given value?\n\"\"\"\n\"\"\"\nDifficulty Level: L2\n\"\"\"\n\"\"\"\nIn ser, find the position of the 2nd largest value greater than the mean.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\nser = pd.Series(np.random.randint(1, 100, 15))\n\"\"\"\n","s":"\"\"\"\n52. How to find the position of the nth largest value greater than a given value?\n\"\"\"\n\"\"\"\nDifficulty Level: L2\n\"\"\"\n\"\"\"\nIn ser, find the position of the 2nd largest value greater than the mean.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\nser = pd.Series(np.random.randint(1, 100, 15))\n\"\"\"\n\n# Input\nser = pd.Series(np.random.randint(1, 100, 15))\n\n# Solution\nprint('ser: ', ser.tolist(), 'mean: ', round(ser.mean()))\nnp.argwhere(ser > ser.mean())[1]"},{"p":"\"\"\"\n53. How to get the last n rows of a dataframe with row sum > 100?\n\"\"\"\n\"\"\"\nDifficulty Level: L2\n\"\"\"\n\"\"\"\nGet the last two rows of df whose row sum is greater than 100.\n\"\"\"\n\"\"\"\ndf = pd.DataFrame(np.random.randint(10, 40, 60).reshape(-1, 4))\n\"\"\"\n","s":"\"\"\"\n53. How to get the last n rows of a dataframe with row sum > 100?\n\"\"\"\n\"\"\"\nDifficulty Level: L2\n\"\"\"\n\"\"\"\nGet the last two rows of df whose row sum is greater than 100.\n\"\"\"\n\"\"\"\ndf = pd.DataFrame(np.random.randint(10, 40, 60).reshape(-1, 4))\n\"\"\"\n\n# Input\ndf = pd.DataFrame(np.random.randint(10, 40, 60).reshape(-1, 4))\n\n# Solution\n# print row sums\nrowsums = df.apply(np.sum, axis=1)\n\n# last two rows with row sum greater than 100\nlast_two_rows = df.iloc[np.where(rowsums > 100)[0][-2:], :]"},{"p":"\"\"\"\n54. How to find and cap outliers from a series or dataframe column?\n\"\"\"\n\"\"\"\nDifficulty Level: L2\n\"\"\"\n\"\"\"\nReplace all values of ser in the lower 5%ile and greater than 95%ile with respective 5th and 95th %ile value.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\nser = pd.Series(np.logspace(-2, 2, 30))\n\"\"\"\n","s":"\"\"\"\n54. How to find and cap outliers from a series or dataframe column?\n\"\"\"\n\"\"\"\nDifficulty Level: L2\n\"\"\"\n\"\"\"\nReplace all values of ser in the lower 5%ile and greater than 95%ile with respective 5th and 95th %ile value.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\nser = pd.Series(np.logspace(-2, 2, 30))\n\"\"\"\n\n# Input\nser = pd.Series(np.logspace(-2, 2, 30))\n\n# Solution\ndef cap_outliers(ser, low_perc, high_perc):\n    low, high = ser.quantile([low_perc, high_perc])\n    print(low_perc, '%ile: ', low, '|', high_perc, '%ile: ', high)\n    ser[ser < low] = low\n    ser[ser > high] = high\n    return(ser)\n\ncapped_ser = cap_outliers(ser, .05, .95)"},{"p":"\"\"\"\n55. How to reshape a dataframe to the largest possible square after removing the negative values?\n\"\"\"\n\"\"\"\nDifficulty Level: L3\n\"\"\"\n\"\"\"\nReshape df to the largest possible square with negative values removed. Drop the smallest values if need be. The order of the positive numbers in the result should remain the same as the original.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\ndf = pd.DataFrame(np.random.randint(-20, 50, 100).reshape(10,-1))\n\"\"\"\n","s":"\"\"\"\n55. How to reshape a dataframe to the largest possible square after removing the negative values?\n\"\"\"\n\"\"\"\nDifficulty Level: L3\n\"\"\"\n\"\"\"\nReshape df to the largest possible square with negative values removed. Drop the smallest values if need be. The order of the positive numbers in the result should remain the same as the original.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\ndf = pd.DataFrame(np.random.randint(-20, 50, 100).reshape(10,-1))\n\"\"\"\n\n# Input\ndf = pd.DataFrame(np.random.randint(-20, 50, 100).reshape(10,-1))\nprint(df)\n\n# Solution\n# Step 1: remove negative values from arr\narr = df[df > 0].values.flatten()\narr_qualified = arr[~np.isnan(arr)]\n\n# Step 2: find side-length of largest possible square\nn = int(np.floor(arr_qualified.shape[0]**.5))\n\n# Step 3: Take top n^2 items without changing positions\ntop_indexes = np.argsort(arr_qualified)[::-1]\noutput = np.take(arr_qualified, sorted(top_indexes[:n**2])).reshape(n, -1)\nprint(output)"},{"p":"\"\"\"\n56. How to swap two rows of a dataframe?\n\"\"\"\n\"\"\"\nDifficulty Level: L2\n\"\"\"\n\"\"\"\nSwap rows 1 and 2 in df.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\ndf = pd.DataFrame(np.arange(25).reshape(5, -1))\n\"\"\"\n","s":"\"\"\"\n56. How to swap two rows of a dataframe?\n\"\"\"\n\"\"\"\nDifficulty Level: L2\n\"\"\"\n\"\"\"\nSwap rows 1 and 2 in df.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\ndf = pd.DataFrame(np.arange(25).reshape(5, -1))\n\"\"\"\n\n# Input\ndf = pd.DataFrame(np.arange(25).reshape(5, -1))\n\n# Solution\ndef swap_rows(df, i1, i2):\n    a, b = df.iloc[i1, :].copy(), df.iloc[i2, :].copy()\n    df.iloc[i1, :], df.iloc[i2, :] = b, a\n    return df\n\nprint(swap_rows(df, 1, 2))"},{"p":"\"\"\"\n57. How to reverse the rows of a dataframe?\n\"\"\"\n\"\"\"\nDifficulty Level: L2\n\"\"\"\n\"\"\"\nReverse all the rows of dataframe df.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\ndf = pd.DataFrame(np.arange(25).reshape(5, -1))\n\"\"\"\n","s":"\"\"\"\n57. How to reverse the rows of a dataframe?\n\"\"\"\n\"\"\"\nDifficulty Level: L2\n\"\"\"\n\"\"\"\nReverse all the rows of dataframe df.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\ndf = pd.DataFrame(np.arange(25).reshape(5, -1))\n\"\"\"\n\n# Input\ndf = pd.DataFrame(np.arange(25).reshape(5, -1))\n\n# Solution 1\ndf.iloc[::-1, :]\n\n# Solution 2\nprint(df.loc[df.index[::-1], :])"},{"p":"\"\"\"\n58. How to create one-hot encodings of a categorical variable (dummy variables)?\n\"\"\"\n\"\"\"\nDifficulty Level: L2\n\"\"\"\n\"\"\"\nGet one-hot encodings for column 'a' in the dataframe df and append it as columns.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\ndf = pd.DataFrame(np.arange(25).reshape(5,-1), columns=list('abcde'))\n    a   b   c   d   e\n0   0   1   2   3   4\n1   5   6   7   8   9\n2  10  11  12  13  14\n3  15  16  17  18  19\n4  20  21  22  23  24\n\"\"\"\n\"\"\"\nOutput\n\"\"\"\n\"\"\"\n   0  5  10  15  20   b   c   d   e\n0  1  0   0   0   0   1   2   3   4\n1  0  1   0   0   0   6   7   8   9\n2  0  0   1   0   0  11  12  13  14\n3  0  0   0   1   0  16  17  18  19\n4  0  0   0   0   1  21  22  23  24\n\"\"\"\n","s":"\"\"\"\n58. How to create one-hot encodings of a categorical variable (dummy variables)?\n\"\"\"\n\"\"\"\nDifficulty Level: L2\n\"\"\"\n\"\"\"\nGet one-hot encodings for column 'a' in the dataframe df and append it as columns.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\ndf = pd.DataFrame(np.arange(25).reshape(5,-1), columns=list('abcde'))\n    a   b   c   d   e\n0   0   1   2   3   4\n1   5   6   7   8   9\n2  10  11  12  13  14\n3  15  16  17  18  19\n4  20  21  22  23  24\n\"\"\"\n\"\"\"\nOutput\n\"\"\"\n\"\"\"\n   0  5  10  15  20   b   c   d   e\n0  1  0   0   0   0   1   2   3   4\n1  0  1   0   0   0   6   7   8   9\n2  0  0   1   0   0  11  12  13  14\n3  0  0   0   1   0  16  17  18  19\n4  0  0   0   0   1  21  22  23  24\n\"\"\"\n\n# Input\ndf = pd.DataFrame(np.arange(25).reshape(5,-1), columns=list('abcde'))\n\n# Solution\ndf_onehot = pd.concat([pd.get_dummies(df['a']), df[list('bcde')]], axis=1)\nprint(df_onehot)"},{"p":"\"\"\"\n60. How to create a new column that contains the row number of nearest column by euclidean distance?\n\"\"\"\n\"\"\"\nCreate a new column such that, each row contains the row number of nearest row-record by euclidean distance.\n\"\"\"\n\"\"\"\nDifficulty Level: L3\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\ndf = pd.DataFrame(np.random.randint(1,100, 40).reshape(10, -1), columns=list('pqrs'), index=list('abcdefghij'))\ndf\n#     p   q   r   s\n# a  57  77  13  62\n# b  68   5  92  24\n# c  74  40  18  37\n# d  80  17  39  60\n# e  93  48  85  33\n# f  69  55   8  11\n# g  39  23  88  53\n# h  63  28  25  61\n# i  18   4  73   7\n# j  79  12  45  34\n\"\"\"\n\"\"\"\nDesired Output\n\"\"\"\n\"\"\"\ndf\n#    p   q   r   s nearest_row   dist\n# a  57  77  13  62           i  116.0\n# b  68   5  92  24           a  114.0\n# c  74  40  18  37           i   91.0\n# d  80  17  39  60           i   89.0\n# e  93  48  85  33           i   92.0\n# f  69  55   8  11           g  100.0\n# g  39  23  88  53           f  100.0\n# h  63  28  25  61           i   88.0\n# i  18   4  73   7           a  116.0\n# j  79  12  45  34           a   81.0\n\"\"\"\n","s":"\"\"\"\n60. How to create a new column that contains the row number of nearest column by euclidean distance?\n\"\"\"\n\"\"\"\nCreate a new column such that, each row contains the row number of nearest row-record by euclidean distance.\n\"\"\"\n\"\"\"\nDifficulty Level: L3\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\ndf = pd.DataFrame(np.random.randint(1,100, 40).reshape(10, -1), columns=list('pqrs'), index=list('abcdefghij'))\ndf\n#     p   q   r   s\n# a  57  77  13  62\n# b  68   5  92  24\n# c  74  40  18  37\n# d  80  17  39  60\n# e  93  48  85  33\n# f  69  55   8  11\n# g  39  23  88  53\n# h  63  28  25  61\n# i  18   4  73   7\n# j  79  12  45  34\n\"\"\"\n\"\"\"\nDesired Output\n\"\"\"\n\"\"\"\ndf\n#    p   q   r   s nearest_row   dist\n# a  57  77  13  62           i  116.0\n# b  68   5  92  24           a  114.0\n# c  74  40  18  37           i   91.0\n# d  80  17  39  60           i   89.0\n# e  93  48  85  33           i   92.0\n# f  69  55   8  11           g  100.0\n# g  39  23  88  53           f  100.0\n# h  63  28  25  61           i   88.0\n# i  18   4  73   7           a  116.0\n# j  79  12  45  34           a   81.0\n\"\"\"\n\ndf = pd.DataFrame(np.random.randint(1,100, 40).reshape(10, -1), columns=list('pqrs'), index=list('abcdefghij'))\n\n# Solution\nimport numpy as np\n\n# init outputs\nnearest_rows = []\nnearest_distance = []\n\n# iterate rows.\nfor i, row in df.iterrows():\n    curr = row\n    rest = df.drop(i)\n    e_dists = {}  # init dict to store euclidean dists for current row.\n    # iterate rest of rows for current row\n    for j, contestant in rest.iterrows():\n        # compute euclidean dist and update e_dists\n        e_dists.update({j: round(np.linalg.norm(curr.values - contestant.values))})\n    # update nearest row to current row and the distance value\n    nearest_rows.append(max(e_dists, key=e_dists.get))\n    nearest_distance.append(max(e_dists.values()))\n\ndf['nearest_row'] = nearest_rows\ndf['dist'] = nearest_distance"},{"p":"\"\"\"\n61. How to know the maximum possible correlation value of each column against other columns?\n\"\"\"\n\"\"\"\nDifficulty Level: L2\n\"\"\"\n\"\"\"\nCompute maximum possible absolute correlation value of each column against other columns in df.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\ndf = pd.DataFrame(np.random.randint(1,100, 80).reshape(8, -1), columns=list('pqrstuvwxy'), index=list('abcdefgh'))\n\"\"\"\n","s":"\"\"\"\n61. How to know the maximum possible correlation value of each column against other columns?\n\"\"\"\n\"\"\"\nDifficulty Level: L2\n\"\"\"\n\"\"\"\nCompute maximum possible absolute correlation value of each column against other columns in df.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\ndf = pd.DataFrame(np.random.randint(1,100, 80).reshape(8, -1), columns=list('pqrstuvwxy'), index=list('abcdefgh'))\n\"\"\"\n\n# Input\ndf = pd.DataFrame(np.random.randint(1,100, 80).reshape(8, -1), columns=list('pqrstuvwxy'), index=list('abcdefgh'))\ndf\n\n# Solution\nabs_corrmat = np.abs(df.corr())\nmax_corr = abs_corrmat.apply(lambda x: sorted(x)[-2])\nprint('Maximum Correlation possible for each column: ', np.round(max_corr.tolist(), 2))"},{"p":"\"\"\"\n62. How to create a column containing the minimum by maximum of each row?\n\"\"\"\n\"\"\"\nDifficulty Level: L2\n\"\"\"\n\"\"\"\nCompute the minimum-by-maximum for every row of df.\n\"\"\"\n\"\"\"\ndf = pd.DataFrame(np.random.randint(1,100, 80).reshape(8, -1))\n\"\"\"\n","s":"\"\"\"\n62. How to create a column containing the minimum by maximum of each row?\n\"\"\"\n\"\"\"\nDifficulty Level: L2\n\"\"\"\n\"\"\"\nCompute the minimum-by-maximum for every row of df.\n\"\"\"\n\"\"\"\ndf = pd.DataFrame(np.random.randint(1,100, 80).reshape(8, -1))\n\"\"\"\n\n# Input\ndf = pd.DataFrame(np.random.randint(1,100, 80).reshape(8, -1))\n\n# Solution 1\nmin_by_max = df.apply(lambda x: np.min(x)/np.max(x), axis=1)\n\n# Solution 2\nmin_by_max = np.min(df, axis=1)/np.max(df, axis=1)"},{"p":"\"\"\"\n63. How to create a column that contains the penultimate value in each row?\n\"\"\"\n\"\"\"\nDifficulty Level: L2\n\"\"\"\n\"\"\"\nCreate a new column 'penultimate' which has the second largest value of each row of df.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\ndf = pd.DataFrame(np.random.randint(1,100, 80).reshape(8, -1))\n\"\"\"\n","s":"\"\"\"\n63. How to create a column that contains the penultimate value in each row?\n\"\"\"\n\"\"\"\nDifficulty Level: L2\n\"\"\"\n\"\"\"\nCreate a new column 'penultimate' which has the second largest value of each row of df.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\ndf = pd.DataFrame(np.random.randint(1,100, 80).reshape(8, -1))\n\"\"\"\n\n# Input\ndf = pd.DataFrame(np.random.randint(1,100, 80).reshape(8, -1))\n\n# Solution\nout = df.apply(lambda x: x.sort_values().unique()[-2], axis=1)\ndf['penultimate'] = out\nprint(df)"},{"p":"\"\"\"\n64. How to normalize all columns in a dataframe?\n\"\"\"\n\"\"\"\nDifficulty Level: L2\n\"\"\"\n\"\"\"\nNormalize all columns of df by subtracting the column mean and divide by standard deviation.Range all columns of df such that the minimum value in each column is 0 and max is 1.\n\"\"\"\n\"\"\"\nDon’t use external packages like sklearn.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\ndf = pd.DataFrame(np.random.randint(1,100, 80).reshape(8, -1))\n\"\"\"\n","s":"\"\"\"\n64. How to normalize all columns in a dataframe?\n\"\"\"\n\"\"\"\nDifficulty Level: L2\n\"\"\"\n\"\"\"\nNormalize all columns of df by subtracting the column mean and divide by standard deviation.Range all columns of df such that the minimum value in each column is 0 and max is 1.\n\"\"\"\n\"\"\"\nDon’t use external packages like sklearn.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\ndf = pd.DataFrame(np.random.randint(1,100, 80).reshape(8, -1))\n\"\"\"\n\n# Input\ndf = pd.DataFrame(np.random.randint(1,100, 80).reshape(8, -1))\n\n# Solution Q1\nout1 = df.apply(lambda x: ((x - x.mean())/x.std()).round(2))\nprint('Solution Q1\\n',out1)\n\n# Solution Q2\nout2 = df.apply(lambda x: ((x.max() - x)/(x.max() - x.min())).round(2))\nprint('Solution Q2\\n', out2)  "},{"p":"\"\"\"\n65. How to compute the correlation of each row with the suceeding row?\n\"\"\"\n\"\"\"\nDifficulty Level: L2\n\"\"\"\n\"\"\"\nCompute the correlation of each row of df with its succeeding row.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\ndf = pd.DataFrame(np.random.randint(1,100, 80).reshape(8, -1))\n\"\"\"\n","s":"\"\"\"\n65. How to compute the correlation of each row with the suceeding row?\n\"\"\"\n\"\"\"\nDifficulty Level: L2\n\"\"\"\n\"\"\"\nCompute the correlation of each row of df with its succeeding row.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\ndf = pd.DataFrame(np.random.randint(1,100, 80).reshape(8, -1))\n\"\"\"\n\n# Input\ndf = pd.DataFrame(np.random.randint(1,100, 80).reshape(8, -1))\n\n# Solution\n[df.iloc[i].corr(df.iloc[i+1]).round(2) for i in range(df.shape[0])[:-1]]"},{"p":"\"\"\"\n66. How to replace both the diagonals of dataframe with 0?\n\"\"\"\n\"\"\"\nDifficulty Level: L2\n\"\"\"\n\"\"\"\nReplace both values in both diagonals of df with 0.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\ndf = pd.DataFrame(np.random.randint(1,100, 100).reshape(10, -1))\ndf\n#     0   1   2   3   4   5   6   7   8   9\n# 0  11  46  26  44  11  62  18  70  68  26\n# 1  87  71  52  50  81  43  83  39   3  59\n# 2  47  76  93  77  73   2   2  16  14  26\n# 3  64  18  74  22  16  37  60   8  66  39\n# 4  10  18  39  98  25   8  32   6   3  29\n# 5  29  91  27  86  23  84  28  31  97  10\n# 6  37  71  70  65   4  72  82  89  12  97\n# 7  65  22  97  75  17  10  43  78  12  77\n# 8  47  57  96  55  17  83  61  85  26  86\n# 9  76  80  28  45  77  12  67  80   7  63\n\"\"\"\n\"\"\"\nDesired output\n\"\"\"\n\"\"\"\n#     0   1   2   3   4   5   6   7   8   9\n# 0   0  46  26  44  11  62  18  70  68   0\n# 1  87   0  52  50  81  43  83  39   0  59\n# 2  47  76   0  77  73   2   2   0  14  26\n# 3  64  18  74   0  16  37   0   8  66  39\n# 4  10  18  39  98   0   0  32   6   3  29\n# 5  29  91  27  86   0   0  28  31  97  10\n# 6  37  71  70   0   4  72   0  89  12  97\n# 7  65  22   0  75  17  10  43   0  12  77\n# 8  47   0  96  55  17  83  61  85   0  86\n# 9   0  80  28  45  77  12  67  80   7   0\n\"\"\"\n","s":"\"\"\"\n66. How to replace both the diagonals of dataframe with 0?\n\"\"\"\n\"\"\"\nDifficulty Level: L2\n\"\"\"\n\"\"\"\nReplace both values in both diagonals of df with 0.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\ndf = pd.DataFrame(np.random.randint(1,100, 100).reshape(10, -1))\ndf\n#     0   1   2   3   4   5   6   7   8   9\n# 0  11  46  26  44  11  62  18  70  68  26\n# 1  87  71  52  50  81  43  83  39   3  59\n# 2  47  76  93  77  73   2   2  16  14  26\n# 3  64  18  74  22  16  37  60   8  66  39\n# 4  10  18  39  98  25   8  32   6   3  29\n# 5  29  91  27  86  23  84  28  31  97  10\n# 6  37  71  70  65   4  72  82  89  12  97\n# 7  65  22  97  75  17  10  43  78  12  77\n# 8  47  57  96  55  17  83  61  85  26  86\n# 9  76  80  28  45  77  12  67  80   7  63\n\"\"\"\n\"\"\"\nDesired output\n\"\"\"\n\"\"\"\n#     0   1   2   3   4   5   6   7   8   9\n# 0   0  46  26  44  11  62  18  70  68   0\n# 1  87   0  52  50  81  43  83  39   0  59\n# 2  47  76   0  77  73   2   2   0  14  26\n# 3  64  18  74   0  16  37   0   8  66  39\n# 4  10  18  39  98   0   0  32   6   3  29\n# 5  29  91  27  86   0   0  28  31  97  10\n# 6  37  71  70   0   4  72   0  89  12  97\n# 7  65  22   0  75  17  10  43   0  12  77\n# 8  47   0  96  55  17  83  61  85   0  86\n# 9   0  80  28  45  77  12  67  80   7   0\n\"\"\"\n\n# Input\ndf = pd.DataFrame(np.random.randint(1,100, 100).reshape(10, -1))\n\n# Solution\nfor i in range(df.shape[0]):\n    df.iat[i, i] = 0\n    df.iat[df.shape[0]-i-1, i] = 0"},{"p":"\"\"\"\n67. How to get the particular group of a groupby dataframe by key?\n\"\"\"\n\"\"\"\nDifficulty Level: L2\n\"\"\"\n\"\"\"\nThis is a question related to understanding of grouped dataframe. From df_grouped, get the group belonging to 'apple' as a dataframe.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\ndf = pd.DataFrame({'col1': ['apple', 'banana', 'orange'] * 3,\n                   'col2': np.random.rand(9),\n                   'col3': np.random.randint(0, 15, 9)})\n\ndf_grouped = df.groupby(['col1'])\n\"\"\"\n\"\"\"\n# Input\ndf = pd.DataFrame({'col1': ['apple', 'banana', 'orange'] * 3,\n                   'col2': np.random.rand(9),\n                   'col3': np.random.randint(0, 15, 9)})\n\ndf_grouped = df.groupby(['col1'])\n\n# Solution 1\ndf_grouped.get_group('apple')\n\n# Solution 2\nfor i, dff in df_grouped:\n    if i == 'apple':\n        print(dff)\n\"\"\"\n\"\"\"\n    col1      col2  col3\n0  apple  0.673434     7\n3  apple  0.182348    14\n6  apple  0.050457     3\n\"\"\"\n","s":""},{"p":"\"\"\"\n68. How to get the n’th largest value of a column when grouped by another column?\n\"\"\"\n\"\"\"\nDifficulty Level: L2\n\"\"\"\n\"\"\"\nIn df, find the second largest value of 'taste' for 'banana'\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\ndf = pd.DataFrame({'fruit': ['apple', 'banana', 'orange'] * 3,\n                   'rating': np.random.rand(9),\n                   'price': np.random.randint(0, 15, 9)})\n\"\"\"\n\"\"\"\n               \n\"\"\"\n","s":"\"\"\"\n68. How to get the n’th largest value of a column when grouped by another column?\n\"\"\"\n\"\"\"\nDifficulty Level: L2\n\"\"\"\n\"\"\"\nIn df, find the second largest value of 'taste' for 'banana'\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\ndf = pd.DataFrame({'fruit': ['apple', 'banana', 'orange'] * 3,\n                   'rating': np.random.rand(9),\n                   'price': np.random.randint(0, 15, 9)})\n\"\"\"\n\"\"\"\n               \n\"\"\"\n\n# Input\ndf = pd.DataFrame({'fruit': ['apple', 'banana', 'orange'] * 3,\n                   'taste': np.random.rand(9),\n                   'price': np.random.randint(0, 15, 9)})\n\nprint(df)\n\n# Solution\ndf_grpd = df['taste'].groupby(df.fruit)\ndf_grpd.get_group('banana').sort_values().iloc[-2]"},{"p":"\"\"\"\n69. How to compute grouped mean on pandas dataframe and keep the grouped column as another column (not index)?\n\"\"\"\n\"\"\"\nDifficulty Level: L1\n\"\"\"\n\"\"\"\nIn df, Compute the mean price of every fruit, while keeping the fruit as another column instead of an index.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\ndf = pd.DataFrame({'fruit': ['apple', 'banana', 'orange'] * 3,\n                   'rating': np.random.rand(9),\n                   'price': np.random.randint(0, 15, 9)})\n\"\"\"\n\"\"\"\n               \n\"\"\"\n","s":"\"\"\"\n69. How to compute grouped mean on pandas dataframe and keep the grouped column as another column (not index)?\n\"\"\"\n\"\"\"\nDifficulty Level: L1\n\"\"\"\n\"\"\"\nIn df, Compute the mean price of every fruit, while keeping the fruit as another column instead of an index.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\ndf = pd.DataFrame({'fruit': ['apple', 'banana', 'orange'] * 3,\n                   'rating': np.random.rand(9),\n                   'price': np.random.randint(0, 15, 9)})\n\"\"\"\n\"\"\"\n               \n\"\"\"\n\n# Input\ndf = pd.DataFrame({'fruit': ['apple', 'banana', 'orange'] * 3,\n                   'rating': np.random.rand(9),\n                   'price': np.random.randint(0, 15, 9)})\n\n# Solution\nout = df.groupby('fruit', as_index=False)['price'].mean()\nprint(out)"},{"p":"\"\"\"\n70. How to join two dataframes by 2 columns so they have only the common rows?\n\"\"\"\n\"\"\"\nDifficulty Level: L2\n\"\"\"\n\"\"\"\nJoin dataframes df1 and df2 by ‘fruit-pazham’ and ‘weight-kilo’.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\ndf1 = pd.DataFrame({'fruit': ['apple', 'banana', 'orange'] * 3,\n                    'weight': ['high', 'medium', 'low'] * 3,\n                    'price': np.random.randint(0, 15, 9)})\n\ndf2 = pd.DataFrame({'pazham': ['apple', 'orange', 'pine'] * 2,\n                    'kilo': ['high', 'low'] * 3,\n                    'price': np.random.randint(0, 15, 6)})\n\"\"\"\n","s":"\"\"\"\n70. How to join two dataframes by 2 columns so they have only the common rows?\n\"\"\"\n\"\"\"\nDifficulty Level: L2\n\"\"\"\n\"\"\"\nJoin dataframes df1 and df2 by ‘fruit-pazham’ and ‘weight-kilo’.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\ndf1 = pd.DataFrame({'fruit': ['apple', 'banana', 'orange'] * 3,\n                    'weight': ['high', 'medium', 'low'] * 3,\n                    'price': np.random.randint(0, 15, 9)})\n\ndf2 = pd.DataFrame({'pazham': ['apple', 'orange', 'pine'] * 2,\n                    'kilo': ['high', 'low'] * 3,\n                    'price': np.random.randint(0, 15, 6)})\n\"\"\"\n\n# Input\ndf1 = pd.DataFrame({'fruit': ['apple', 'banana', 'orange'] * 3,\n                    'weight': ['high', 'medium', 'low'] * 3,\n                    'price': np.random.randint(0, 15, 9)})\n\ndf2 = pd.DataFrame({'pazham': ['apple', 'orange', 'pine'] * 2,\n                    'kilo': ['high', 'low'] * 3,\n                    'price': np.random.randint(0, 15, 6)})\n\n# Solution\npd.merge(df1, df2, how='inner', left_on=['fruit', 'weight'], right_on=['pazham', 'pounds'], suffixes=['_left', '_right'])"},{"p":"\"\"\"\n71. How to remove rows from a dataframe that are present in another dataframe?\n\"\"\"\n\"\"\"\nDifficulty Level: L3\n\"\"\"\n\"\"\"\nFrom df1, remove the rows that are present in df2. All three columns must be the same.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\ndf1 = pd.DataFrame({'fruit': ['apple', 'banana', 'orange'] * 3,\n                    'weight': ['high', 'medium', 'low'] * 3,\n                    'price': np.random.randint(0, 15, 9)})\n\ndf2 = pd.DataFrame({'pazham': ['apple', 'orange', 'pine'] * 2,\n                    'kilo': ['high', 'low'] * 3,\n                    'price': np.random.randint(0, 15, 6)})\n\"\"\"\n\"\"\"\n# Input\ndf1 = pd.DataFrame({'fruit': ['apple', 'orange', 'banana'] * 3,\n                    'weight': ['high', 'medium', 'low'] * 3,\n                    'price': np.arange(9)})\n\ndf2 = pd.DataFrame({'fruit': ['apple', 'orange', 'pine'] * 2,\n                    'weight': ['high', 'medium'] * 3,\n                    'price': np.arange(6)})\n\n\n# Solution\nprint(df1[~df1.isin(df2).all(1)])\n\"\"\"\n","s":"\"\"\"\n71. How to remove rows from a dataframe that are present in another dataframe?\n\"\"\"\n\"\"\"\nDifficulty Level: L3\n\"\"\"\n\"\"\"\nFrom df1, remove the rows that are present in df2. All three columns must be the same.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\ndf1 = pd.DataFrame({'fruit': ['apple', 'banana', 'orange'] * 3,\n                    'weight': ['high', 'medium', 'low'] * 3,\n                    'price': np.random.randint(0, 15, 9)})\n\ndf2 = pd.DataFrame({'pazham': ['apple', 'orange', 'pine'] * 2,\n                    'kilo': ['high', 'low'] * 3,\n                    'price': np.random.randint(0, 15, 6)})\n\"\"\"\n\n# Input\ndf1 = pd.DataFrame({'fruit': ['apple', 'orange', 'banana'] * 3,\n                    'weight': ['high', 'medium', 'low'] * 3,\n                    'price': np.arange(9)})\n\ndf2 = pd.DataFrame({'fruit': ['apple', 'orange', 'pine'] * 2,\n                    'weight': ['high', 'medium'] * 3,\n                    'price': np.arange(6)})\n\n\n# Solution\nprint(df1[~df1.isin(df2).all(1)])"},{"p":"\"\"\"\n72. How to get the positions where values of two columns match?\n\"\"\"\n\"\"\"\nDifficulty Level: L2\n\"\"\"\n\"\"\"\n \n\"\"\"\n","s":"\"\"\"\n72. How to get the positions where values of two columns match?\n\"\"\"\n\"\"\"\nDifficulty Level: L2\n\"\"\"\n\"\"\"\n \n\"\"\"\n\n# Input\ndf = pd.DataFrame({'fruit1': np.random.choice(['apple', 'orange', 'banana'], 10),\n                    'fruit2': np.random.choice(['apple', 'orange', 'banana'], 10)})\n\n# Solution\nnp.where(df.fruit1 == df.fruit2)"},{"p":"\"\"\"\n73. How to create lags and leads of a column in a dataframe?\n\"\"\"\n\"\"\"\nDifficulty Level: L2\n\"\"\"\n\"\"\"\nCreate two new columns in df, one of which is a lag1 (shift column a down by 1 row) of column ‘a’ and the other is a lead1 (shift column b up by 1 row).\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\ndf = pd.DataFrame(np.random.randint(1, 100, 20).reshape(-1, 4), columns = list('abcd'))\n\n    a   b   c   d\n0  66  34  76  47\n1  20  86  10  81\n2  75  73  51  28\n3   1   1   9  83\n4  30  47  67   4\n\"\"\"\n\"\"\"\nDesired Output\n\"\"\"\n\"\"\"\n    a   b   c   d  a_lag1  b_lead1\n0  66  34  76  47     NaN     86.0\n1  20  86  10  81    66.0     73.0\n2  75  73  51  28    20.0      1.0\n3   1   1   9  83    75.0     47.0\n4  30  47  67   4     1.0      NaN\n\"\"\"\n","s":"\"\"\"\n73. How to create lags and leads of a column in a dataframe?\n\"\"\"\n\"\"\"\nDifficulty Level: L2\n\"\"\"\n\"\"\"\nCreate two new columns in df, one of which is a lag1 (shift column a down by 1 row) of column ‘a’ and the other is a lead1 (shift column b up by 1 row).\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\ndf = pd.DataFrame(np.random.randint(1, 100, 20).reshape(-1, 4), columns = list('abcd'))\n\n    a   b   c   d\n0  66  34  76  47\n1  20  86  10  81\n2  75  73  51  28\n3   1   1   9  83\n4  30  47  67   4\n\"\"\"\n\"\"\"\nDesired Output\n\"\"\"\n\"\"\"\n    a   b   c   d  a_lag1  b_lead1\n0  66  34  76  47     NaN     86.0\n1  20  86  10  81    66.0     73.0\n2  75  73  51  28    20.0      1.0\n3   1   1   9  83    75.0     47.0\n4  30  47  67   4     1.0      NaN\n\"\"\"\n\n# Input\ndf = pd.DataFrame(np.random.randint(1, 100, 20).reshape(-1, 4), columns = list('abcd'))\n\n# Solution\ndf['a_lag1'] = df['a'].shift(1)\ndf['b_lead1'] = df['b'].shift(-1)\nprint(df)"},{"p":"\"\"\"\n74. How to get the frequency of unique values in the entire dataframe?\n\"\"\"\n\"\"\"\nDifficulty Level: L2\n\"\"\"\n\"\"\"\nGet the frequency of unique values in the entire dataframe df.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\ndf = pd.DataFrame(np.random.randint(1, 10, 20).reshape(-1, 4), columns = list('abcd'))\n\"\"\"\n","s":"\"\"\"\n74. How to get the frequency of unique values in the entire dataframe?\n\"\"\"\n\"\"\"\nDifficulty Level: L2\n\"\"\"\n\"\"\"\nGet the frequency of unique values in the entire dataframe df.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\ndf = pd.DataFrame(np.random.randint(1, 10, 20).reshape(-1, 4), columns = list('abcd'))\n\"\"\"\n\n# Input\ndf = pd.DataFrame(np.random.randint(1, 10, 20).reshape(-1, 4), columns = list('abcd'))\n\n# Solution\npd.value_counts(df.values.ravel())"},{"p":"\"\"\"\n75. How to split a text column into two separate columns?\n\"\"\"\n\"\"\"\nDifficulty Level: L2\n\"\"\"\n\"\"\"\nSplit the string column in df to form a dataframe with 3 columns as shown.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\ndf = pd.DataFrame([\"STD, City    State\",\n\"33, Kolkata    West Bengal\",\n\"44, Chennai    Tamil Nadu\",\n\"40, Hyderabad    Telengana\",\n\"80, Bangalore    Karnataka\"], columns=['row'])\n\nprint(df)\n#>                         row\n#> 0          STD, City\\tState\n#> 1  33, Kolkata\\tWest Bengal\n#> 2   44, Chennai\\tTamil Nadu\n#> 3  40, Hyderabad\\tTelengana\n#> 4  80, Bangalore\\tKarnataka\n\"\"\"\n\"\"\"\nDesired Output\n\"\"\"\n\"\"\"\n0 STD        City        State\n1  33     Kolkata  West Bengal\n2  44     Chennai   Tamil Nadu\n3  40   Hyderabad    Telengana\n4  80   Bangalore    Karnataka\n\"\"\"\n\"\"\"\n# Input\ndf = pd.DataFrame([\"STD, City    State\",\n\"33, Kolkata    West Bengal\",\n\"44, Chennai    Tamil Nadu\",\n\"40, Hyderabad    Telengana\",\n\"80, Bangalore    Karnataka\"], columns=['row'])\n\n# Solution\ndf_out = df.row.str.split(',|\\t', expand=True)\n\n# Make first row as header\nnew_header = df_out.iloc[0]\ndf_out = df_out[1:]\ndf_out.columns = new_header\nprint(df_out)0 STD        City        State\n1  33     Kolkata  West Bengal\n2  44     Chennai   Tamil Nadu\n3  40   Hyderabad    Telengana\n4  80   Bangalore    Karnataka\n\"\"\"\n\"\"\"\nTo be continued . .\n\"\"\"\n\"\"\"\nRelatedNumpy Tutorial Part 2 - Vital Functions for Data AnalysisNumpy is the core package for data analysis and scientific computing in python. This is part 2 of a mega numpy tutorial. In this part, I go into the details of the advanced features of numpy that are essential for data analysis and manipulations. Introduction In part 1 of the…February 14, 2018In “Python”101 NumPy Exercises for Data Analysis (Python)The goal of the numpy exercises is to serve as a reference as well as to get you to apply numpy beyond the basics. The questions are of 4 levels of difficulties with L1 being the easiest to L4 being the hardest. If you want a quick refresher on numpy,…February 26, 2018In “Python”Numpy Tutorial Part 1 - Introduction to ArraysThis is part 1 of the numpy tutorial covering all the core aspects of performing data manipulation and analysis with numpy's ndarrays. Numpy is the most basic and a powerful package for scientific computing and data manipulation in python. 1. Introduction to Numpy Numpy is the most basic and a…February 7, 2018In “Python”\n\"\"\"\n\"\"\"\n\n  \n  \n\n    \n      \n    \n\n\n    \n\n      \n        \n          \n            \n\n  \n    \n      \n    \n  \n\n          \n\n          \n            Sharing is caring!\n          \n        \n        \n          \n\n          \n          \n            \n              212\n              \n\n                \n                \n\n                \n                \n                  Share\n                  \n\n                \n              \n            \n          \n            \n              0\n              \n\n                \n                \n\n                \n                \n                  Tweet\n                  \n\n                \n              \n            \n          \n            \n              230\n              \n\n                \n                \n\n                \n                \n                  Pin\n                  \n\n                \n              \n            \n          \n            \n              0\n              \n\n                \n                \n\n                \n                \n                  Share\n                  \n\n                \n              \n            \n          \n            \n              0\n              \n\n                \n                \n\n                \n                \n                  Mail\n                  \n\n                \n              \n            \n          \n            \n              0\n              \n\n                \n                \n\n                \n                \n                  Share\n                  \n\n                \n              \n            \n          \n        \n      \n      \n        \n      \n    \n  \n\n\n\"\"\"\n","s":"\"\"\"\n75. How to split a text column into two separate columns?\n\"\"\"\n\"\"\"\nDifficulty Level: L2\n\"\"\"\n\"\"\"\nSplit the string column in df to form a dataframe with 3 columns as shown.\n\"\"\"\n\"\"\"\nInput\n\"\"\"\n\"\"\"\ndf = pd.DataFrame([\"STD, City    State\",\n\"33, Kolkata    West Bengal\",\n\"44, Chennai    Tamil Nadu\",\n\"40, Hyderabad    Telengana\",\n\"80, Bangalore    Karnataka\"], columns=['row'])\n\nprint(df)\n#>                         row\n#> 0          STD, City\\tState\n#> 1  33, Kolkata\\tWest Bengal\n#> 2   44, Chennai\\tTamil Nadu\n#> 3  40, Hyderabad\\tTelengana\n#> 4  80, Bangalore\\tKarnataka\n\"\"\"\n\"\"\"\nDesired Output\n\"\"\"\n\"\"\"\n0 STD        City        State\n1  33     Kolkata  West Bengal\n2  44     Chennai   Tamil Nadu\n3  40   Hyderabad    Telengana\n4  80   Bangalore    Karnataka\n\"\"\"\n\n# Input\ndf = pd.DataFrame([\"STD, City    State\",\n\"33, Kolkata    West Bengal\",\n\"44, Chennai    Tamil Nadu\",\n\"40, Hyderabad    Telengana\",\n\"80, Bangalore    Karnataka\"], columns=['row'])\n\n# Solution\ndf_out = df.row.str.split(',|\\t', expand=True)\n\n# Make first row as header\nnew_header = df_out.iloc[0]\ndf_out = df_out[1:]\ndf_out.columns = new_header\nprint(df_out)"}]